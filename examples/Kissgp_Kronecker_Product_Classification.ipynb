{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "Below is the example for a Gaussian Process classification example using GpyTorch :class:`.VariationalGaussianProcessClassifier`\n",
    "        \n",
    "This example shows how to use a GridInducingVariationalGP module. This classification module is designed for when the function you're modeling has 2-3 dimensional inputs and you don't believe that the output can be additively decomposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpytorch and gpwrapper in a directory above\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# We make an nxn grid of training points\n",
    "# In [0,1]x[0,1] spaced every 1/(n-1)\n",
    "n = 30\n",
    "train_x = torch.zeros(int(pow(n, 2)), 2)\n",
    "train_y = torch.zeros(int(pow(n, 2)))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        train_x[i * n + j][0] = float(i) / (n - 1)\n",
    "        train_x[i * n + j][1] = float(j) / (n - 1)\n",
    "        # True function is checkerboard of 1/3x1/3 squares with labels of -1 or 1\n",
    "        train_y[i * n + j] = pow(-1, int(3 * i / n + int(3 * j / n)))\n",
    "train_x = Variable(train_x)\n",
    "train_y = Variable(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from gpwrapper import VariationalGaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the GP model\n",
    "# Our classification model is just KISS-GP run through a Bernoulli likelihood\n",
    "class GPClassificationModel(gpytorch.models.GridInducingVariationalGP):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel, self).__init__(grid_size=20, grid_bounds=[(-2, 2), (-2, 2)])\n",
    "        # Near-zero mean\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        # RBF as universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Learned mean is near-zero\n",
    "        mean_x = self.mean_module(x)\n",
    "        # Get predictive and scale\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        # Store as Gaussian\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m649.4601\u001b[0m  1.3550\n",
      "      2      \u001b[36m348.2982\u001b[0m  0.8616\n",
      "      3      \u001b[36m234.9531\u001b[0m  0.8928\n",
      "      4      237.1428  0.8615\n",
      "      5      \u001b[36m234.5687\u001b[0m  0.9749\n",
      "      6      \u001b[36m179.3226\u001b[0m  1.0592\n",
      "      7      \u001b[36m115.2692\u001b[0m  1.0036\n",
      "      8       \u001b[36m79.5032\u001b[0m  0.9102\n",
      "      9       \u001b[36m70.2538\u001b[0m  0.8582\n",
      "     10       \u001b[36m64.6359\u001b[0m  0.8371\n",
      "     11       \u001b[36m48.1511\u001b[0m  0.9787\n",
      "     12       \u001b[36m34.0512\u001b[0m  1.0397\n",
      "     13       \u001b[36m22.3320\u001b[0m  1.2646\n",
      "     14       \u001b[36m19.9965\u001b[0m  1.5686\n",
      "     15       \u001b[36m14.4135\u001b[0m  0.9883\n",
      "     16       \u001b[36m13.9751\u001b[0m  0.9478\n",
      "     17       \u001b[36m13.3118\u001b[0m  0.9963\n",
      "     18       \u001b[36m11.9616\u001b[0m  0.9332\n",
      "     19       \u001b[36m10.3263\u001b[0m  0.8636\n",
      "     20        \u001b[36m9.2378\u001b[0m  0.8872\n",
      "     21        \u001b[36m7.9615\u001b[0m  1.4550\n",
      "     22        \u001b[36m6.7948\u001b[0m  1.1092\n",
      "     23        \u001b[36m5.8493\u001b[0m  0.8926\n",
      "     24        \u001b[36m5.2778\u001b[0m  0.8805\n",
      "     25        \u001b[36m4.5622\u001b[0m  0.9098\n",
      "     26        \u001b[36m3.8875\u001b[0m  0.8473\n",
      "     27        \u001b[36m3.4642\u001b[0m  0.8702\n",
      "     28        3.5304  0.8849\n",
      "     29        \u001b[36m3.2793\u001b[0m  0.9551\n",
      "     30        \u001b[36m3.1617\u001b[0m  0.8127\n",
      "     31        \u001b[36m2.6908\u001b[0m  0.8177\n",
      "     32        2.9249  0.8250\n",
      "     33        3.0562  1.1350\n",
      "     34        2.8322  0.8136\n",
      "     35        2.7942  0.8236\n",
      "     36        2.8716  0.8330\n",
      "     37        2.9039  0.8035\n",
      "     38        2.8087  0.8379\n",
      "     39        \u001b[36m2.5337\u001b[0m  0.8200\n",
      "     40        \u001b[36m2.4958\u001b[0m  0.8106\n",
      "     41        \u001b[36m2.4328\u001b[0m  0.8142\n",
      "     42        \u001b[36m2.3755\u001b[0m  0.8212\n",
      "     43        \u001b[36m2.3298\u001b[0m  0.8133\n",
      "     44        2.5193  0.8118\n",
      "     45        \u001b[36m2.2963\u001b[0m  1.0676\n",
      "     46        2.4449  0.8444\n",
      "     47        \u001b[36m2.1673\u001b[0m  0.8124\n",
      "     48        \u001b[36m2.0782\u001b[0m  0.8208\n",
      "     49        \u001b[36m2.0658\u001b[0m  0.8141\n",
      "     50        \u001b[36m1.8700\u001b[0m  0.8121\n",
      "     51        1.9547  0.8076\n",
      "     52        2.1822  0.7991\n",
      "     53        2.0329  0.8128\n",
      "     54        2.1200  0.8094\n",
      "     55        1.9015  0.8648\n",
      "     56        2.0939  0.8562\n",
      "     57        \u001b[36m1.8118\u001b[0m  1.0559\n",
      "     58        1.8702  0.9404\n",
      "     59        1.9675  0.8291\n",
      "     60        2.0205  0.8172\n",
      "     61        \u001b[36m1.7360\u001b[0m  0.8308\n",
      "     62        \u001b[36m1.7000\u001b[0m  0.8003\n",
      "     63        \u001b[36m1.6916\u001b[0m  0.8004\n",
      "     64        1.9511  0.7970\n",
      "     65        \u001b[36m1.6733\u001b[0m  0.8075\n",
      "     66        \u001b[36m1.6479\u001b[0m  0.8246\n",
      "     67        1.7551  0.8070\n",
      "     68        \u001b[36m1.4837\u001b[0m  0.8068\n",
      "     69        1.5178  0.9370\n",
      "     70        \u001b[36m1.4332\u001b[0m  0.9896\n",
      "     71        1.5613  1.0292\n",
      "     72        \u001b[36m1.3933\u001b[0m  1.0832\n",
      "     73        \u001b[36m1.3179\u001b[0m  1.3190\n",
      "     74        1.4770  0.9685\n",
      "     75        1.4525  0.9918\n",
      "     76        1.3576  0.8663\n",
      "     77        1.5933  1.2493\n",
      "     78        1.5977  1.4488\n",
      "     79        1.4059  2.0452\n",
      "     80        1.3511  1.0776\n",
      "     81        \u001b[36m1.3022\u001b[0m  0.9074\n",
      "     82        1.4321  1.3380\n",
      "     83        \u001b[36m1.2790\u001b[0m  0.9678\n",
      "     84        \u001b[36m1.2723\u001b[0m  1.0115\n",
      "     85        \u001b[36m1.2352\u001b[0m  0.9456\n",
      "     86        1.3694  0.9242\n",
      "     87        \u001b[36m1.2236\u001b[0m  1.0054\n",
      "     88        \u001b[36m1.2124\u001b[0m  1.1858\n",
      "     89        1.2762  0.9320\n",
      "     90        \u001b[36m1.1366\u001b[0m  1.1068\n",
      "     91        1.1675  0.9549\n",
      "     92        1.1729  0.9277\n",
      "     93        1.1853  1.0154\n",
      "     94        1.1551  0.9261\n",
      "     95        \u001b[36m1.0767\u001b[0m  0.8616\n",
      "     96        1.0808  0.9625\n",
      "     97        1.1604  0.9034\n",
      "     98        \u001b[36m1.0476\u001b[0m  1.1095\n",
      "     99        1.2173  1.0108\n",
      "    100        1.0723  0.8895\n",
      "    101        1.1879  0.8829\n",
      "    102        1.1767  0.9032\n",
      "    103        \u001b[36m1.0064\u001b[0m  0.8745\n",
      "    104        1.0498  0.9826\n",
      "    105        \u001b[36m0.9795\u001b[0m  1.3438\n",
      "    106        \u001b[36m0.9106\u001b[0m  1.2105\n",
      "    107        1.0709  1.2170\n",
      "    108        0.9793  1.2684\n",
      "    109        1.1071  1.0053\n",
      "    110        1.0490  0.9672\n",
      "    111        0.9959  0.8835\n",
      "    112        1.0544  0.9907\n",
      "    113        0.9259  0.8860\n",
      "    114        1.0854  0.8999\n",
      "    115        0.9479  1.0876\n",
      "    116        0.9724  0.8174\n",
      "    117        1.0106  0.9066\n",
      "    118        \u001b[36m0.8760\u001b[0m  0.8977\n",
      "    119        0.9064  1.3001\n",
      "    120        1.0910  0.9598\n",
      "    121        0.9277  0.9372\n",
      "    122        0.9561  0.8530\n",
      "    123        0.9805  1.0372\n",
      "    124        0.9433  1.5661\n",
      "    125        0.9406  1.1588\n",
      "    126        0.9735  0.9428\n",
      "    127        0.9828  1.2368\n",
      "    128        0.9017  3.0828\n",
      "    129        \u001b[36m0.8526\u001b[0m  1.4833\n",
      "    130        \u001b[36m0.8415\u001b[0m  1.0433\n",
      "    131        0.9191  1.2020\n",
      "    132        0.9254  0.9071\n",
      "    133        \u001b[36m0.8160\u001b[0m  1.5057\n",
      "    134        \u001b[36m0.8075\u001b[0m  1.6611\n",
      "    135        0.8112  1.7665\n",
      "    136        \u001b[36m0.7929\u001b[0m  1.0740\n",
      "    137        0.8453  1.7099\n",
      "    138        0.8310  1.2419\n",
      "    139        0.8502  0.8195\n",
      "    140        0.7971  0.8126\n",
      "    141        0.8547  0.8173\n",
      "    142        \u001b[36m0.7777\u001b[0m  0.8190\n",
      "    143        0.8135  0.8701\n",
      "    144        0.8130  1.0792\n",
      "    145        0.7796  0.8452\n",
      "    146        0.8151  1.3796\n",
      "    147        0.8462  1.4407\n",
      "    148        0.7805  1.0517\n",
      "    149        \u001b[36m0.7410\u001b[0m  1.0000\n",
      "    150        0.7896  1.0468\n",
      "    151        0.7608  0.9916\n",
      "    152        0.7934  0.8960\n",
      "    153        0.7549  1.2625\n",
      "    154        0.7895  1.0244\n",
      "    155        0.7455  0.8510\n",
      "    156        0.7477  1.0263\n",
      "    157        0.7676  0.8665\n",
      "    158        0.7511  1.0343\n",
      "    159        0.7704  0.9540\n",
      "    160        \u001b[36m0.7317\u001b[0m  0.9998\n",
      "    161        0.7392  0.9949\n",
      "    162        0.7507  0.8799\n",
      "    163        0.7461  0.8858\n",
      "    164        0.7326  1.1994\n",
      "    165        \u001b[36m0.7125\u001b[0m  1.0290\n",
      "    166        \u001b[36m0.7102\u001b[0m  1.1409\n",
      "    167        \u001b[36m0.6832\u001b[0m  1.2191\n",
      "    168        0.7080  1.0222\n",
      "    169        0.7701  0.8654\n",
      "    170        0.7343  1.2374\n",
      "    171        0.7071  1.1523\n",
      "    172        0.7086  1.0422\n",
      "    173        \u001b[36m0.6789\u001b[0m  1.3639\n",
      "    174        0.7180  1.5604\n",
      "    175        0.7261  0.9362\n",
      "    176        0.7301  1.0120\n",
      "    177        0.6888  0.8538\n",
      "    178        0.6972  0.9723\n",
      "    179        \u001b[36m0.6624\u001b[0m  1.0015\n",
      "    180        0.6903  0.8389\n",
      "    181        0.6724  1.0963\n",
      "    182        0.6920  1.2472\n",
      "    183        0.6893  1.1670\n",
      "    184        0.6690  1.2540\n",
      "    185        \u001b[36m0.6470\u001b[0m  0.8604\n",
      "    186        0.6499  1.0321\n",
      "    187        0.6579  1.1476\n",
      "    188        0.6484  0.9096\n",
      "    189        \u001b[36m0.6312\u001b[0m  0.8607\n",
      "    190        \u001b[36m0.6226\u001b[0m  1.1646\n",
      "    191        0.6349  1.0300\n",
      "    192        0.6315  0.8316\n",
      "    193        0.6636  0.9245\n",
      "    194        0.6420  1.7492\n",
      "    195        0.6384  2.2719\n",
      "    196        0.6241  0.9584\n",
      "    197        0.6461  1.2892\n",
      "    198        0.6243  1.4095\n",
      "    199        \u001b[36m0.6027\u001b[0m  1.0164\n",
      "    200        0.6505  1.1184\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Wrap the model into our GP Wrapper\n",
    "GPWrapper = VariationalGaussianProcessClassifier(\n",
    "    module = GPClassificationModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 200,\n",
    ")\n",
    "\n",
    "# Step 3: Find optimal model hyperparameters\n",
    "GPWrapper.fit(X=train_x, y=train_y)\n",
    "\n",
    "# Step 4: Prediction\n",
    "# Test points are 100x100 grid of [0,1]x[0,1] with spacing of 1/99\n",
    "n = 100\n",
    "test_x = Variable(torch.zeros(int(pow(n, 2)), 2))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        test_x.data[i * n + j][0] = float(i) / (n-1)\n",
    "        test_x.data[i * n + j][1] = float(j) / (n-1)\n",
    "        \n",
    "observed_pred = GPWrapper.predict_proba(X=test_x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (*) Step 5: Plotting\n",
    "# Initialize figiure an axis\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # prob<0.5 --> label -1 // prob>0.5 --> label 1\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1).data.numpy()\n",
    "    # Colors = yellow for 1, red for -1\n",
    "    color = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        if pred_labels[i] == 1:\n",
    "            color.append('y')\n",
    "        else:\n",
    "            color.append('r')\n",
    "    # Plot data a scatter plot\n",
    "    ax.scatter(test_x.data[:, 0].numpy(), test_x.data[:, 1].numpy(), color=color, s=1)\n",
    "    ax.set_ylim([-0.5, 1.5])\n",
    "    ax.set_title(title)\n",
    "# Plot predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Predicted Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn Pipeline\n",
    "Same as skorch, our wrapper provides an sklearn-compatible interface, so it is possible to put it into an sklearn Pipeline. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m386.2593\u001b[0m  0.8515\n",
      "      2      \u001b[36m132.1532\u001b[0m  0.9494\n",
      "      3       \u001b[36m87.2927\u001b[0m  0.8463\n",
      "      4       \u001b[36m75.6586\u001b[0m  0.8345\n",
      "      5       \u001b[36m64.4967\u001b[0m  0.8571\n",
      "      6       \u001b[36m52.8795\u001b[0m  0.8878\n",
      "      7       \u001b[36m36.7115\u001b[0m  0.8390\n",
      "      8       \u001b[36m26.4053\u001b[0m  1.0263\n",
      "      9       \u001b[36m17.5674\u001b[0m  0.9819\n",
      "     10       \u001b[36m13.0037\u001b[0m  0.9560\n",
      "     11       \u001b[36m10.4763\u001b[0m  1.0817\n",
      "     12        \u001b[36m8.4145\u001b[0m  0.9868\n",
      "     13        \u001b[36m7.3189\u001b[0m  0.8987\n",
      "     14        \u001b[36m6.4830\u001b[0m  0.8444\n",
      "     15        \u001b[36m5.8577\u001b[0m  0.8474\n",
      "     16        \u001b[36m5.2921\u001b[0m  0.8765\n",
      "     17        \u001b[36m4.9967\u001b[0m  0.8755\n",
      "     18        \u001b[36m4.5161\u001b[0m  1.0906\n",
      "     19        \u001b[36m4.0612\u001b[0m  1.2341\n",
      "     20        \u001b[36m3.4626\u001b[0m  0.9563\n",
      "     21        \u001b[36m3.4187\u001b[0m  1.4757\n",
      "     22        \u001b[36m2.9888\u001b[0m  1.1645\n",
      "     23        \u001b[36m2.9279\u001b[0m  1.2327\n",
      "     24        \u001b[36m2.7794\u001b[0m  1.1040\n",
      "     25        \u001b[36m2.5536\u001b[0m  1.1987\n",
      "     26        \u001b[36m2.4978\u001b[0m  0.9362\n",
      "     27        \u001b[36m2.4660\u001b[0m  1.3754\n",
      "     28        \u001b[36m2.3243\u001b[0m  0.9531\n",
      "     29        \u001b[36m2.2057\u001b[0m  0.9580\n",
      "     30        2.2242  1.1164\n",
      "     31        \u001b[36m2.0527\u001b[0m  1.1879\n",
      "     32        2.1280  0.9426\n",
      "     33        \u001b[36m1.7294\u001b[0m  1.3437\n",
      "     34        1.9339  1.4078\n",
      "     35        1.7984  1.1235\n",
      "     36        \u001b[36m1.7031\u001b[0m  1.0220\n",
      "     37        1.9074  1.0847\n",
      "     38        \u001b[36m1.6810\u001b[0m  1.0688\n",
      "     39        1.7102  0.9106\n",
      "     40        \u001b[36m1.5334\u001b[0m  1.2328\n",
      "     41        \u001b[36m1.4633\u001b[0m  1.0285\n",
      "     42        \u001b[36m1.3883\u001b[0m  0.8783\n",
      "     43        \u001b[36m1.3856\u001b[0m  0.8662\n",
      "     44        1.4398  0.8584\n",
      "     45        \u001b[36m1.3776\u001b[0m  0.8661\n",
      "     46        \u001b[36m1.3115\u001b[0m  0.9616\n",
      "     47        1.3513  1.0288\n",
      "     48        1.3162  1.0113\n",
      "     49        \u001b[36m1.2915\u001b[0m  0.9684\n",
      "     50        1.3021  1.0452\n",
      "     51        \u001b[36m1.2060\u001b[0m  1.1020\n",
      "     52        \u001b[36m1.1816\u001b[0m  0.9009\n",
      "     53        1.1900  0.9825\n",
      "     54        \u001b[36m1.0810\u001b[0m  0.9038\n",
      "     55        1.1600  0.9328\n",
      "     56        \u001b[36m1.0731\u001b[0m  0.9323\n",
      "     57        1.0892  0.9652\n",
      "     58        \u001b[36m1.0650\u001b[0m  0.9131\n",
      "     59        \u001b[36m1.0559\u001b[0m  1.0433\n",
      "     60        \u001b[36m0.9620\u001b[0m  1.0458\n",
      "     61        0.9760  1.4024\n",
      "     62        \u001b[36m0.9303\u001b[0m  1.5011\n",
      "     63        0.9658  0.9695\n",
      "     64        1.0428  1.1269\n",
      "     65        \u001b[36m0.8574\u001b[0m  1.6445\n",
      "     66        0.9064  1.2756\n",
      "     67        0.8976  1.0547\n",
      "     68        0.8693  1.0713\n",
      "     69        \u001b[36m0.8482\u001b[0m  1.1540\n",
      "     70        0.8853  1.2064\n",
      "     71        0.8804  1.1589\n",
      "     72        0.8483  1.2243\n",
      "     73        0.8523  1.2121\n",
      "     74        \u001b[36m0.8385\u001b[0m  1.5299\n",
      "     75        \u001b[36m0.7907\u001b[0m  1.5143\n",
      "     76        0.7975  1.1983\n",
      "     77        0.8113  1.8007\n",
      "     78        \u001b[36m0.7596\u001b[0m  1.8327\n",
      "     79        0.8155  1.6489\n",
      "     80        \u001b[36m0.7595\u001b[0m  1.2383\n",
      "     81        0.7699  1.6671\n",
      "     82        0.7824  1.4721\n",
      "     83        \u001b[36m0.7255\u001b[0m  1.5272\n",
      "     84        0.7690  1.4875\n",
      "     85        0.7382  2.3015\n",
      "     86        0.7511  1.8171\n",
      "     87        0.7303  1.8901\n",
      "     88        \u001b[36m0.7206\u001b[0m  1.6543\n",
      "     89        \u001b[36m0.6980\u001b[0m  1.3355\n",
      "     90        0.7186  1.3798\n",
      "     91        \u001b[36m0.6780\u001b[0m  1.4856\n",
      "     92        0.6872  1.2160\n",
      "     93        0.7021  1.1792\n",
      "     94        \u001b[36m0.6683\u001b[0m  1.1718\n",
      "     95        0.6718  1.1386\n",
      "     96        \u001b[36m0.6610\u001b[0m  1.1521\n",
      "     97        \u001b[36m0.6545\u001b[0m  1.1474\n",
      "     98        0.6554  1.1523\n",
      "     99        0.6613  1.2367\n",
      "    100        \u001b[36m0.6539\u001b[0m  1.2415\n",
      "    101        \u001b[36m0.6302\u001b[0m  1.1461\n",
      "    102        \u001b[36m0.6257\u001b[0m  1.1634\n",
      "    103        \u001b[36m0.6218\u001b[0m  1.1446\n",
      "    104        \u001b[36m0.6182\u001b[0m  1.1656\n",
      "    105        0.6210  1.1519\n",
      "    106        0.6376  1.1372\n",
      "    107        \u001b[36m0.6048\u001b[0m  1.1319\n",
      "    108        0.6130  1.2495\n",
      "    109        0.6105  1.2578\n",
      "    110        \u001b[36m0.5942\u001b[0m  1.1654\n",
      "    111        0.6036  1.1506\n",
      "    112        \u001b[36m0.5777\u001b[0m  1.1484\n",
      "    113        0.6085  1.1634\n",
      "    114        0.5813  1.1444\n",
      "    115        0.6082  1.2200\n",
      "    116        \u001b[36m0.5775\u001b[0m  1.1619\n",
      "    117        \u001b[36m0.5715\u001b[0m  1.3672\n",
      "    118        \u001b[36m0.5577\u001b[0m  1.1486\n",
      "    119        0.5599  1.1564\n",
      "    120        0.5654  1.1606\n",
      "    121        \u001b[36m0.5355\u001b[0m  1.1716\n",
      "    122        0.5554  1.1604\n",
      "    123        0.5532  1.1579\n",
      "    124        0.5544  1.1498\n",
      "    125        \u001b[36m0.5340\u001b[0m  1.1704\n",
      "    126        \u001b[36m0.5278\u001b[0m  1.3643\n",
      "    127        \u001b[36m0.5272\u001b[0m  1.1692\n",
      "    128        0.5546  1.1767\n",
      "    129        \u001b[36m0.5154\u001b[0m  1.1607\n",
      "    130        0.5244  1.1542\n",
      "    131        \u001b[36m0.5143\u001b[0m  1.1574\n",
      "    132        \u001b[36m0.5038\u001b[0m  1.1332\n",
      "    133        0.5231  1.1647\n",
      "    134        0.5110  1.1801\n",
      "    135        \u001b[36m0.4948\u001b[0m  1.3143\n",
      "    136        0.5076  1.1614\n",
      "    137        0.4994  1.1417\n",
      "    138        0.5013  1.1522\n",
      "    139        \u001b[36m0.4852\u001b[0m  1.1961\n",
      "    140        \u001b[36m0.4849\u001b[0m  1.1556\n",
      "    141        0.5044  1.1515\n",
      "    142        0.4985  1.1313\n",
      "    143        0.5122  1.1762\n",
      "    144        \u001b[36m0.4765\u001b[0m  1.4061\n",
      "    145        \u001b[36m0.4669\u001b[0m  1.1691\n",
      "    146        0.4780  1.1761\n",
      "    147        0.4923  1.1287\n",
      "    148        \u001b[36m0.4649\u001b[0m  1.1744\n",
      "    149        0.4879  1.1948\n",
      "    150        0.4745  1.2209\n",
      "    151        0.4680  1.1457\n",
      "    152        \u001b[36m0.4567\u001b[0m  1.2981\n",
      "    153        0.4662  1.2091\n",
      "    154        \u001b[36m0.4562\u001b[0m  1.1950\n",
      "    155        \u001b[36m0.4509\u001b[0m  1.1643\n",
      "    156        0.4544  1.1589\n",
      "    157        0.4575  1.1472\n",
      "    158        0.4637  1.1598\n",
      "    159        \u001b[36m0.4362\u001b[0m  1.1386\n",
      "    160        0.4379  1.1697\n",
      "    161        0.4573  1.3954\n",
      "    162        0.4450  1.1428\n",
      "    163        0.4609  1.1789\n",
      "    164        \u001b[36m0.4290\u001b[0m  1.1413\n",
      "    165        0.4637  1.1789\n",
      "    166        \u001b[36m0.4289\u001b[0m  1.2007\n",
      "    167        0.4381  1.1736\n",
      "    168        \u001b[36m0.4251\u001b[0m  1.1891\n",
      "    169        0.4292  1.1773\n",
      "    170        \u001b[36m0.4050\u001b[0m  1.4082\n",
      "    171        0.4351  1.1680\n",
      "    172        0.4339  1.1740\n",
      "    173        0.4342  1.1646\n",
      "    174        0.4144  1.1780\n",
      "    175        0.4344  1.2010\n",
      "    176        \u001b[36m0.4021\u001b[0m  0.8660\n",
      "    177        0.4125  0.8298\n",
      "    178        0.4144  0.8254\n",
      "    179        0.4072  1.0248\n",
      "    180        \u001b[36m0.3988\u001b[0m  0.9168\n",
      "    181        0.4225  0.8324\n",
      "    182        0.4042  0.8335\n",
      "    183        0.4152  0.8447\n",
      "    184        0.4097  0.8078\n",
      "    185        \u001b[36m0.3895\u001b[0m  0.8226\n",
      "    186        0.4169  0.8200\n",
      "    187        0.3924  0.8187\n",
      "    188        0.4073  0.8311\n",
      "    189        0.3942  0.8233\n",
      "    190        0.3943  0.8220\n",
      "    191        0.3944  0.9891\n",
      "    192        0.3919  0.9347\n",
      "    193        0.3931  0.8351\n",
      "    194        0.3948  0.8322\n",
      "    195        \u001b[36m0.3789\u001b[0m  0.8650\n",
      "    196        0.3843  0.8321\n",
      "    197        0.3923  0.8234\n",
      "    198        0.3803  0.8329\n",
      "    199        \u001b[36m0.3694\u001b[0m  0.8253\n",
      "    200        0.3708  0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('GP', <class 'gpwrapper.VariationalGaussianProcessClassifier'>[initialized](\n",
       "  module_=GPClassificationModel(\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): GridKernel(\n",
       "      (base_kernel_module): RBFKernel()\n",
       "    )\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "GPWrapper = VariationalGaussianProcessClassifier(\n",
    "    module = GPClassificationModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 200,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('GP', GPWrapper),\n",
    "])\n",
    "\n",
    "pipe.fit(X=train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "Same as skorch, another advantage of our wrapper is that you can perform an sklearn GridSearchCV or RandomizedSearchCV in Gpytorch to find optimal hyperparameters. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m966.8924\u001b[0m  1.1913\n",
      "      2      \u001b[36m862.1198\u001b[0m  1.2398\n",
      "      3      \u001b[36m769.5782\u001b[0m  1.0578\n",
      "      4      \u001b[36m688.9012\u001b[0m  1.0580\n",
      "      5      \u001b[36m618.5310\u001b[0m  1.2943\n",
      "      6      \u001b[36m557.8286\u001b[0m  1.0703\n",
      "      7      \u001b[36m505.2246\u001b[0m  1.1415\n",
      "      8      \u001b[36m460.0349\u001b[0m  1.3623\n",
      "      9      \u001b[36m421.2902\u001b[0m  0.9600\n",
      "     10      \u001b[36m388.3403\u001b[0m  0.9571\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m966.9047\u001b[0m  1.2005\n",
      "      2      \u001b[36m862.4175\u001b[0m  0.9572\n",
      "      3      \u001b[36m770.2535\u001b[0m  0.9769\n",
      "      4      \u001b[36m689.5417\u001b[0m  0.9778\n",
      "      5      \u001b[36m619.6158\u001b[0m  1.1508\n",
      "      6      \u001b[36m558.9026\u001b[0m  1.0852\n",
      "      7      \u001b[36m506.4880\u001b[0m  0.8752\n",
      "      8      \u001b[36m461.5730\u001b[0m  0.8522\n",
      "      9      \u001b[36m423.0173\u001b[0m  0.8264\n",
      "     10      \u001b[36m390.1455\u001b[0m  1.2654\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m964.2571\u001b[0m  1.2524\n",
      "      2      \u001b[36m860.2063\u001b[0m  1.0371\n",
      "      3      \u001b[36m768.0756\u001b[0m  0.8790\n",
      "      4      \u001b[36m687.5983\u001b[0m  0.9071\n",
      "      5      \u001b[36m617.9907\u001b[0m  0.8746\n",
      "      6      \u001b[36m557.5901\u001b[0m  0.9249\n",
      "      7      \u001b[36m505.8167\u001b[0m  1.1984\n",
      "      8      \u001b[36m460.9265\u001b[0m  1.3316\n",
      "      9      \u001b[36m422.6473\u001b[0m  1.0167\n",
      "     10      \u001b[36m390.1574\u001b[0m  1.0003\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m959.4686\u001b[0m  1.0863\n",
      "      2      \u001b[36m855.2411\u001b[0m  1.0114\n",
      "      3      \u001b[36m763.2968\u001b[0m  0.8820\n",
      "      4      \u001b[36m682.8306\u001b[0m  0.9640\n",
      "      5      \u001b[36m612.9104\u001b[0m  0.9022\n",
      "      6      \u001b[36m552.4350\u001b[0m  1.3106\n",
      "      7      \u001b[36m500.3644\u001b[0m  1.4234\n",
      "      8      \u001b[36m455.6538\u001b[0m  0.9686\n",
      "      9      \u001b[36m417.3937\u001b[0m  0.9635\n",
      "     10      \u001b[36m384.8268\u001b[0m  1.0972\n",
      "     11      \u001b[36m356.9086\u001b[0m  1.4141\n",
      "     12      \u001b[36m332.9515\u001b[0m  1.1830\n",
      "     13      \u001b[36m312.5437\u001b[0m  1.3600\n",
      "     14      \u001b[36m294.8402\u001b[0m  1.2131\n",
      "     15      \u001b[36m279.6565\u001b[0m  1.2382\n",
      "     16      \u001b[36m266.2310\u001b[0m  1.2143\n",
      "     17      \u001b[36m254.4036\u001b[0m  1.1795\n",
      "     18      \u001b[36m244.0348\u001b[0m  1.4650\n",
      "     19      \u001b[36m234.5484\u001b[0m  1.9597\n",
      "     20      \u001b[36m225.9820\u001b[0m  1.4699\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m969.3255\u001b[0m  1.6830\n",
      "      2      \u001b[36m864.6300\u001b[0m  1.6734\n",
      "      3      \u001b[36m772.2200\u001b[0m  1.3302\n",
      "      4      \u001b[36m691.5252\u001b[0m  1.5119\n",
      "      5      \u001b[36m621.3533\u001b[0m  1.2650\n",
      "      6      \u001b[36m560.7850\u001b[0m  1.9225\n",
      "      7      \u001b[36m508.3699\u001b[0m  1.5256\n",
      "      8      \u001b[36m463.3588\u001b[0m  1.6886\n",
      "      9      \u001b[36m424.9603\u001b[0m  1.2551\n",
      "     10      \u001b[36m391.9738\u001b[0m  0.9263\n",
      "     11      \u001b[36m363.9298\u001b[0m  1.4151\n",
      "     12      \u001b[36m339.8224\u001b[0m  0.8855\n",
      "     13      \u001b[36m319.2061\u001b[0m  1.1992\n",
      "     14      \u001b[36m301.3333\u001b[0m  1.4289\n",
      "     15      \u001b[36m285.9939\u001b[0m  0.8639\n",
      "     16      \u001b[36m272.5554\u001b[0m  0.8621\n",
      "     17      \u001b[36m260.6063\u001b[0m  0.8646\n",
      "     18      \u001b[36m250.1041\u001b[0m  0.8544\n",
      "     19      \u001b[36m240.4808\u001b[0m  0.8397\n",
      "     20      \u001b[36m231.8254\u001b[0m  0.9632\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m967.4525\u001b[0m  0.8783\n",
      "      2      \u001b[36m862.8406\u001b[0m  0.9800\n",
      "      3      \u001b[36m770.6612\u001b[0m  0.8858\n",
      "      4      \u001b[36m690.1184\u001b[0m  0.9941\n",
      "      5      \u001b[36m620.0122\u001b[0m  1.2899\n",
      "      6      \u001b[36m559.4869\u001b[0m  1.0025\n",
      "      7      \u001b[36m507.2348\u001b[0m  0.8739\n",
      "      8      \u001b[36m462.4550\u001b[0m  0.8593\n",
      "      9      \u001b[36m424.0576\u001b[0m  0.8777\n",
      "     10      \u001b[36m391.2638\u001b[0m  0.9878\n",
      "     11      \u001b[36m363.2641\u001b[0m  1.0256\n",
      "     12      \u001b[36m339.1551\u001b[0m  0.8785\n",
      "     13      \u001b[36m318.5469\u001b[0m  1.2210\n",
      "     14      \u001b[36m300.8175\u001b[0m  1.3005\n",
      "     15      \u001b[36m285.4585\u001b[0m  1.2590\n",
      "     16      \u001b[36m271.9765\u001b[0m  0.9663\n",
      "     17      \u001b[36m260.0934\u001b[0m  0.9198\n",
      "     18      \u001b[36m249.4572\u001b[0m  0.9589\n",
      "     19      \u001b[36m239.8631\u001b[0m  1.1278\n",
      "     20      \u001b[36m231.1966\u001b[0m  1.0441\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m966.0172\u001b[0m  0.9453\n",
      "      2      \u001b[36m769.7867\u001b[0m  0.9233\n",
      "      3      \u001b[36m618.3012\u001b[0m  1.0908\n",
      "      4      \u001b[36m505.7261\u001b[0m  1.0605\n",
      "      5      \u001b[36m423.4803\u001b[0m  1.8133\n",
      "      6      \u001b[36m363.7551\u001b[0m  0.9515\n",
      "      7      \u001b[36m320.9257\u001b[0m  0.8884\n",
      "      8      \u001b[36m290.6034\u001b[0m  0.9760\n",
      "      9      \u001b[36m268.7571\u001b[0m  0.9416\n",
      "     10      \u001b[36m252.2689\u001b[0m  0.8774\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m967.4954\u001b[0m  0.9223\n",
      "      2      \u001b[36m771.5955\u001b[0m  1.1548\n",
      "      3      \u001b[36m620.2217\u001b[0m  1.2114\n",
      "      4      \u001b[36m507.7939\u001b[0m  1.0924\n",
      "      5      \u001b[36m425.4518\u001b[0m  1.2235\n",
      "      6      \u001b[36m365.7233\u001b[0m  0.8627\n",
      "      7      \u001b[36m323.1888\u001b[0m  0.8803\n",
      "      8      \u001b[36m292.9831\u001b[0m  0.8845\n",
      "      9      \u001b[36m271.2283\u001b[0m  0.8778\n",
      "     10      \u001b[36m255.0431\u001b[0m  0.8876\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m964.4443\u001b[0m  0.8492\n",
      "      2      \u001b[36m768.2927\u001b[0m  0.8632\n",
      "      3      \u001b[36m616.9224\u001b[0m  0.8832\n",
      "      4      \u001b[36m504.4208\u001b[0m  0.8653\n",
      "      5      \u001b[36m422.3255\u001b[0m  0.8572\n",
      "      6      \u001b[36m362.8254\u001b[0m  1.0606\n",
      "      7      \u001b[36m320.4192\u001b[0m  0.9388\n",
      "      8      \u001b[36m290.2260\u001b[0m  0.9427\n",
      "      9      \u001b[36m268.5940\u001b[0m  0.9204\n",
      "     10      \u001b[36m252.2892\u001b[0m  0.8713\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m960.0439\u001b[0m  1.3349\n",
      "      2      \u001b[36m764.9634\u001b[0m  0.9520\n",
      "      3      \u001b[36m614.3956\u001b[0m  0.8534\n",
      "      4      \u001b[36m502.6819\u001b[0m  0.8444\n",
      "      5      \u001b[36m421.0098\u001b[0m  1.0196\n",
      "      6      \u001b[36m361.9207\u001b[0m  1.2219\n",
      "      7      \u001b[36m319.8094\u001b[0m  2.4066\n",
      "      8      \u001b[36m289.8394\u001b[0m  1.0366\n",
      "      9      \u001b[36m268.3284\u001b[0m  0.9325\n",
      "     10      \u001b[36m252.0939\u001b[0m  0.9272\n",
      "     11      \u001b[36m239.0223\u001b[0m  1.2604\n",
      "     12      \u001b[36m227.5969\u001b[0m  0.9825\n",
      "     13      \u001b[36m217.0415\u001b[0m  1.4461\n",
      "     14      \u001b[36m206.8123\u001b[0m  1.1481\n",
      "     15      \u001b[36m196.5195\u001b[0m  1.3680\n",
      "     16      \u001b[36m186.0653\u001b[0m  0.8792\n",
      "     17      \u001b[36m175.4029\u001b[0m  0.9274\n",
      "     18      \u001b[36m164.7808\u001b[0m  1.2104\n",
      "     19      \u001b[36m154.2307\u001b[0m  0.8728\n",
      "     20      \u001b[36m143.8199\u001b[0m  0.8426\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m965.6123\u001b[0m  1.0423\n",
      "      2      \u001b[36m770.7314\u001b[0m  0.9075\n",
      "      3      \u001b[36m620.1721\u001b[0m  1.4511\n",
      "      4      \u001b[36m508.2665\u001b[0m  2.5369\n",
      "      5      \u001b[36m426.5533\u001b[0m  1.1819\n",
      "      6      \u001b[36m367.5168\u001b[0m  0.8941\n",
      "      7      \u001b[36m324.9413\u001b[0m  0.8324\n",
      "      8      \u001b[36m294.7695\u001b[0m  1.1155\n",
      "      9      \u001b[36m273.2814\u001b[0m  1.1600\n",
      "     10      \u001b[36m256.8719\u001b[0m  1.2189\n",
      "     11      \u001b[36m243.8617\u001b[0m  1.1429\n",
      "     12      \u001b[36m232.6189\u001b[0m  1.0313\n",
      "     13      \u001b[36m221.8025\u001b[0m  1.5992\n",
      "     14      \u001b[36m211.5556\u001b[0m  1.0274\n",
      "     15      \u001b[36m200.9432\u001b[0m  1.1534\n",
      "     16      \u001b[36m190.7038\u001b[0m  0.9590\n",
      "     17      \u001b[36m179.8033\u001b[0m  1.1150\n",
      "     18      \u001b[36m169.2923\u001b[0m  1.1284\n",
      "     19      \u001b[36m158.5484\u001b[0m  0.9455\n",
      "     20      \u001b[36m148.3215\u001b[0m  0.9537\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m954.6688\u001b[0m  1.0277\n",
      "      2      \u001b[36m759.7679\u001b[0m  0.9611\n",
      "      3      \u001b[36m609.2037\u001b[0m  1.2343\n",
      "      4      \u001b[36m497.3988\u001b[0m  1.0237\n",
      "      5      \u001b[36m416.1655\u001b[0m  0.9059\n",
      "      6      \u001b[36m357.3669\u001b[0m  1.1830\n",
      "      7      \u001b[36m315.2372\u001b[0m  1.1028\n",
      "      8      \u001b[36m285.4799\u001b[0m  0.8707\n",
      "      9      \u001b[36m264.0683\u001b[0m  0.9127\n",
      "     10      \u001b[36m247.9344\u001b[0m  0.8849\n",
      "     11      \u001b[36m235.1514\u001b[0m  0.9272\n",
      "     12      \u001b[36m223.8011\u001b[0m  1.2553\n",
      "     13      \u001b[36m213.5347\u001b[0m  1.2514\n",
      "     14      \u001b[36m203.1599\u001b[0m  1.0339\n",
      "     15      \u001b[36m192.9197\u001b[0m  0.8938\n",
      "     16      \u001b[36m182.6940\u001b[0m  0.9443\n",
      "     17      \u001b[36m172.2761\u001b[0m  0.9022\n",
      "     18      \u001b[36m161.7667\u001b[0m  0.8959\n",
      "     19      \u001b[36m151.4416\u001b[0m  0.8819\n",
      "     20      \u001b[36m141.1733\u001b[0m  1.0975\n",
      "\n",
      " gs.best_score_ = 0.5555555555555556, gs.best_params = {'lr': 0.01, 'max_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "}\n",
    "\n",
    "GPWrapper = VariationalGaussianProcessClassifier(\n",
    "    module = GPClassificationModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 200,\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(GPWrapper, params, refit=False, cv=3, scoring='accuracy',\n",
    "                  return_train_score=False)  # Use a different scoring function maybe?\n",
    "\n",
    "gs.fit(X=train_x, y=train_y)\n",
    "print('\\n gs.best_score_ = {}, gs.best_params = {}'.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Need to comment out **line 157 - 161** of `.../anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/__init__.py`\n",
    "```\n",
    "if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n",
    "                           indices.dtype.kind == 'i'):\n",
    "    # This is often substantially faster than X[indices]\n",
    "    return X.take(indices, axis=0)\n",
    "else:\n",
    "```\n",
    "Otherwise an error would occur saying\n",
    "`argument 'index' (position 1) must be Tensor, not numpy.ndarray`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
