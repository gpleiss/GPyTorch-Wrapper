{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "Below is the example for a Gaussian Process classification example using GpyTorch :class:`.VariationalGaussianProcessRegressor`\n",
    "\n",
    "This example shows how to perform GP regression, but using variational inference rather than exact inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpytorch and gpwrapper in a directory above\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from gpwrapper import VariationalGaussianProcessRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training set\n",
    "# We're going to learn a sine function\n",
    "train_x = torch.linspace(0, 1, 1000)\n",
    "train_y = torch.sin(train_x * (4 * math.pi)) + torch.randn(train_x.size()) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the GP model\n",
    "class GPRegressionModel(gpytorch.models.GridInducingVariationalGP):\n",
    "    def __init__(self):\n",
    "        super(GPRegressionModel, self).__init__(grid_size=64, grid_bounds=[(-2, 2)])\n",
    "        self.mean_module = gpytorch.means.ConstantMean(constant_bounds=[-1e-5,1e-5])\n",
    "        self.covar_module = gpytorch.kernels.RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', torch.nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        return gpytorch.random_variables.GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m160.1326\u001b[0m  0.1749\n",
      "      2      \u001b[36m112.6650\u001b[0m  0.0619\n",
      "      3       \u001b[36m83.8052\u001b[0m  0.0571\n",
      "      4       \u001b[36m67.7176\u001b[0m  0.0563\n",
      "      5       \u001b[36m54.6686\u001b[0m  0.0541\n",
      "      6       \u001b[36m40.9633\u001b[0m  0.0575\n",
      "      7       \u001b[36m28.7714\u001b[0m  0.0786\n",
      "      8       \u001b[36m20.1120\u001b[0m  0.0670\n",
      "      9       \u001b[36m14.8302\u001b[0m  0.0702\n",
      "     10       \u001b[36m11.5988\u001b[0m  0.0637\n",
      "     11        \u001b[36m9.2122\u001b[0m  0.0704\n",
      "     12        \u001b[36m7.8804\u001b[0m  0.0563\n",
      "     13        \u001b[36m7.1130\u001b[0m  0.0533\n",
      "     14        7.2201  0.0546\n",
      "     15        7.6093  0.0597\n",
      "     16        8.0882  0.0566\n",
      "     17        8.5868  0.0587\n",
      "     18        8.9517  0.0564\n",
      "     19        9.0864  0.0571\n",
      "     20        8.9275  0.0650\n",
      "     21        8.5280  0.0628\n",
      "     22        7.9406  0.0650\n",
      "     23        7.2908  0.0602\n",
      "     24        \u001b[36m6.6422\u001b[0m  0.0568\n",
      "     25        \u001b[36m5.9429\u001b[0m  0.0578\n",
      "     26        \u001b[36m5.2081\u001b[0m  0.0662\n",
      "     27        \u001b[36m4.4777\u001b[0m  0.0557\n",
      "     28        \u001b[36m3.8278\u001b[0m  0.0557\n",
      "     29        \u001b[36m3.3090\u001b[0m  0.0550\n",
      "     30        \u001b[36m2.9067\u001b[0m  0.0550\n",
      "     31        \u001b[36m2.6257\u001b[0m  0.0562\n",
      "     32        \u001b[36m2.5878\u001b[0m  0.0552\n",
      "     33        \u001b[36m2.5394\u001b[0m  0.0567\n",
      "     34        \u001b[36m2.4725\u001b[0m  0.0596\n",
      "     35        \u001b[36m2.4027\u001b[0m  0.0732\n",
      "     36        \u001b[36m2.3360\u001b[0m  0.0590\n",
      "     37        \u001b[36m2.2632\u001b[0m  0.0566\n",
      "     38        \u001b[36m2.1944\u001b[0m  0.0587\n",
      "     39        \u001b[36m2.1360\u001b[0m  0.0566\n",
      "     40        \u001b[36m2.0866\u001b[0m  0.0593\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Wrap the model into our GP Wrapper\n",
    "GPWrapper = VariationalGaussianProcessRegressor(\n",
    "    module = GPRegressionModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 40,\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR\n",
    ")\n",
    "\n",
    "# Step 3: Find optimal model hyperparameters\n",
    "# See dkl_mnist.ipynb for explanation of use_toeplitz\n",
    "with gpytorch.settings.use_toeplitz(False), gpytorch.beta_features.diagonal_correction():\n",
    "    GPWrapper.fit(X=train_x, y=train_y)\n",
    "    \n",
    "# Step 4: Prediction\n",
    "test_x = torch.autograd.Variable(torch.linspace(0, 1, 51))\n",
    "with gpytorch.settings.max_cg_iterations(2000), gpytorch.settings.use_toeplitz(False), gpytorch.beta_features.diagonal_correction():\n",
    "    observed_pred = GPWrapper.predict_proba(X=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a24de8518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower, upper = observed_pred.confidence_region()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "ax.plot(train_x.cpu().numpy(), train_y.cpu().numpy(), 'k*')\n",
    "ax.plot(test_x.data.cpu().numpy(), observed_pred.mean().data.cpu().numpy(), 'b')\n",
    "ax.fill_between(test_x.data.cpu().numpy(), lower.data.cpu().numpy(), upper.data.cpu().numpy(), alpha=0.5)\n",
    "ax.set_ylim([-3, 3])\n",
    "ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn Pipeline\n",
    "Same as skorch, our wrapper provides an sklearn-compatible interface, so it is possible to put it into an sklearn Pipeline. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m154.1074\u001b[0m  0.1020\n",
      "      2      \u001b[36m111.3461\u001b[0m  0.1358\n",
      "      3       \u001b[36m84.1519\u001b[0m  0.0968\n",
      "      4       \u001b[36m67.0284\u001b[0m  0.0954\n",
      "      5       \u001b[36m53.0918\u001b[0m  0.0984\n",
      "      6       \u001b[36m39.0577\u001b[0m  0.0931\n",
      "      7       \u001b[36m26.6068\u001b[0m  0.0920\n",
      "      8       \u001b[36m17.5448\u001b[0m  0.1336\n",
      "      9       \u001b[36m11.9226\u001b[0m  0.1121\n",
      "     10        \u001b[36m8.6647\u001b[0m  0.1281\n",
      "     11        \u001b[36m6.8155\u001b[0m  0.2047\n",
      "     12        \u001b[36m5.9278\u001b[0m  0.1842\n",
      "     13        6.0741  0.3196\n",
      "     14        6.6459  0.1657\n",
      "     15        7.5476  0.0907\n",
      "     16        8.4454  0.3113\n",
      "     17        9.2006  0.1302\n",
      "     18        9.6477  0.0882\n",
      "     19        9.8191  0.0862\n",
      "     20        9.6600  0.1050\n",
      "     21        9.2706  0.1673\n",
      "     22        8.6795  0.1241\n",
      "     23        7.9611  0.0885\n",
      "     24        7.1674  0.0870\n",
      "     25        6.3700  0.1834\n",
      "     26        \u001b[36m5.5993\u001b[0m  0.1074\n",
      "     27        \u001b[36m4.8628\u001b[0m  0.0868\n",
      "     28        \u001b[36m4.2076\u001b[0m  0.0903\n",
      "     29        \u001b[36m3.6475\u001b[0m  0.2002\n",
      "     30        \u001b[36m3.1964\u001b[0m  0.1058\n",
      "     31        \u001b[36m2.8434\u001b[0m  0.1116\n",
      "     32        \u001b[36m2.7981\u001b[0m  0.0952\n",
      "     33        \u001b[36m2.7485\u001b[0m  0.0920\n",
      "     34        \u001b[36m2.6854\u001b[0m  0.0902\n",
      "     35        \u001b[36m2.6202\u001b[0m  0.1046\n",
      "     36        \u001b[36m2.5525\u001b[0m  0.1066\n",
      "     37        \u001b[36m2.4789\u001b[0m  0.0950\n",
      "     38        \u001b[36m2.4120\u001b[0m  0.0944\n",
      "     39        \u001b[36m2.3492\u001b[0m  0.0956\n",
      "     40        \u001b[36m2.2933\u001b[0m  0.0908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('GP', <class 'gpwrapper.VariationalGaussianProcessRegressor'>[initialized](\n",
       "  module_=GPRegressionModel(\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): GridKernel(\n",
       "      (base_kernel_module): RBFKernel()\n",
       "    )\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('GP', GPWrapper),\n",
    "])\n",
    "\n",
    "pipe.fit(X=train_x.unsqueeze(-1), y=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "Same as skorch, another advantage of our wrapper is that you can perform an sklearn GridSearchCV or RandomizedSearchCV in Gpytorch to find optimal hyperparameters. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m259.9103\u001b[0m  0.0744\n",
      "      2      \u001b[36m249.8280\u001b[0m  0.0820\n",
      "      3      \u001b[36m240.5561\u001b[0m  0.0778\n",
      "      4      \u001b[36m232.0551\u001b[0m  0.0767\n",
      "      5      \u001b[36m224.2543\u001b[0m  0.0750\n",
      "      6      \u001b[36m217.0878\u001b[0m  0.0760\n",
      "      7      \u001b[36m210.4865\u001b[0m  0.0749\n",
      "      8      \u001b[36m204.3922\u001b[0m  0.1579\n",
      "      9      \u001b[36m198.7413\u001b[0m  0.3527\n",
      "     10      \u001b[36m198.1927\u001b[0m  0.1444\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m205.4134\u001b[0m  0.1107\n",
      "      2      \u001b[36m196.1169\u001b[0m  0.0813\n",
      "      3      \u001b[36m187.6001\u001b[0m  0.1320\n",
      "      4      \u001b[36m179.8238\u001b[0m  0.1295\n",
      "      5      \u001b[36m172.7172\u001b[0m  0.1576\n",
      "      6      \u001b[36m166.2191\u001b[0m  0.2016\n",
      "      7      \u001b[36m160.2486\u001b[0m  0.1850\n",
      "      8      \u001b[36m154.7591\u001b[0m  0.1647\n",
      "      9      \u001b[36m149.6802\u001b[0m  0.1025\n",
      "     10      \u001b[36m149.1978\u001b[0m  0.0967\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m164.2393\u001b[0m  0.0949\n",
      "      2      \u001b[36m155.7902\u001b[0m  0.1038\n",
      "      3      \u001b[36m148.1001\u001b[0m  0.0864\n",
      "      4      \u001b[36m141.1123\u001b[0m  0.1661\n",
      "      5      \u001b[36m134.7659\u001b[0m  0.1341\n",
      "      6      \u001b[36m128.9964\u001b[0m  0.3451\n",
      "      7      \u001b[36m123.7408\u001b[0m  0.2135\n",
      "      8      \u001b[36m118.9432\u001b[0m  0.1071\n",
      "      9      \u001b[36m114.5416\u001b[0m  0.1154\n",
      "     10      \u001b[36m114.1239\u001b[0m  0.0816\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m206.8811\u001b[0m  0.1326\n",
      "      2      \u001b[36m197.4931\u001b[0m  0.1331\n",
      "      3      \u001b[36m188.9034\u001b[0m  0.1288\n",
      "      4      \u001b[36m181.0624\u001b[0m  0.1046\n",
      "      5      \u001b[36m173.9044\u001b[0m  0.0956\n",
      "      6      \u001b[36m167.3764\u001b[0m  0.1886\n",
      "      7      \u001b[36m161.3946\u001b[0m  0.1014\n",
      "      8      \u001b[36m155.9122\u001b[0m  0.0742\n",
      "      9      \u001b[36m150.8703\u001b[0m  0.1351\n",
      "     10      \u001b[36m146.2185\u001b[0m  0.1100\n",
      "     11      \u001b[36m141.9024\u001b[0m  0.0753\n",
      "     12      \u001b[36m137.8844\u001b[0m  0.0736\n",
      "     13      \u001b[36m134.1095\u001b[0m  0.0740\n",
      "     14      \u001b[36m130.5594\u001b[0m  0.0756\n",
      "     15      \u001b[36m127.1909\u001b[0m  0.0738\n",
      "     16      \u001b[36m123.9883\u001b[0m  0.0749\n",
      "     17      \u001b[36m123.6685\u001b[0m  0.1627\n",
      "     18      \u001b[36m123.3520\u001b[0m  0.2063\n",
      "     19      \u001b[36m123.0392\u001b[0m  0.1593\n",
      "     20      \u001b[36m122.7242\u001b[0m  0.1441\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m189.1814\u001b[0m  0.2626\n",
      "      2      \u001b[36m180.2394\u001b[0m  0.2389\n",
      "      3      \u001b[36m172.0656\u001b[0m  0.1033\n",
      "      4      \u001b[36m164.6234\u001b[0m  0.1097\n",
      "      5      \u001b[36m157.8454\u001b[0m  0.1286\n",
      "      6      \u001b[36m151.6469\u001b[0m  0.1175\n",
      "      7      \u001b[36m145.9828\u001b[0m  0.1388\n",
      "      8      \u001b[36m140.7932\u001b[0m  0.1520\n",
      "      9      \u001b[36m136.0096\u001b[0m  0.1166\n",
      "     10      \u001b[36m131.5831\u001b[0m  0.1027\n",
      "     11      \u001b[36m127.4776\u001b[0m  0.1482\n",
      "     12      \u001b[36m123.6400\u001b[0m  0.0725\n",
      "     13      \u001b[36m120.0350\u001b[0m  0.0718\n",
      "     14      \u001b[36m116.6361\u001b[0m  0.0716\n",
      "     15      \u001b[36m113.4159\u001b[0m  0.0716\n",
      "     16      \u001b[36m110.3563\u001b[0m  0.0730\n",
      "     17      \u001b[36m110.0504\u001b[0m  0.0717\n",
      "     18      \u001b[36m109.7545\u001b[0m  0.0862\n",
      "     19      \u001b[36m109.4502\u001b[0m  0.0860\n",
      "     20      \u001b[36m109.1492\u001b[0m  0.0849\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m182.6329\u001b[0m  0.0800\n",
      "      2      \u001b[36m173.9281\u001b[0m  0.0886\n",
      "      3      \u001b[36m165.9527\u001b[0m  0.0846\n",
      "      4      \u001b[36m158.6895\u001b[0m  0.0773\n",
      "      5      \u001b[36m152.0845\u001b[0m  0.0760\n",
      "      6      \u001b[36m146.0787\u001b[0m  0.2408\n",
      "      7      \u001b[36m140.5981\u001b[0m  0.3236\n",
      "      8      \u001b[36m135.5905\u001b[0m  0.2356\n",
      "      9      \u001b[36m130.9958\u001b[0m  0.1448\n",
      "     10      \u001b[36m126.7561\u001b[0m  0.0789\n",
      "     11      \u001b[36m122.8199\u001b[0m  0.0716\n",
      "     12      \u001b[36m119.1631\u001b[0m  0.0690\n",
      "     13      \u001b[36m115.7302\u001b[0m  0.0697\n",
      "     14      \u001b[36m112.4883\u001b[0m  0.0717\n",
      "     15      \u001b[36m109.4270\u001b[0m  0.0709\n",
      "     16      \u001b[36m106.5142\u001b[0m  0.0772\n",
      "     17      \u001b[36m106.2335\u001b[0m  0.0766\n",
      "     18      \u001b[36m105.9472\u001b[0m  0.0791\n",
      "     19      \u001b[36m105.6551\u001b[0m  0.0733\n",
      "     20      \u001b[36m105.3718\u001b[0m  0.1195\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m179.8029\u001b[0m  0.1248\n",
      "      2      \u001b[36m162.4155\u001b[0m  0.1022\n",
      "      3      \u001b[36m148.0233\u001b[0m  0.1296\n",
      "      4      \u001b[36m136.1569\u001b[0m  0.1305\n",
      "      5      \u001b[36m126.2626\u001b[0m  0.1280\n",
      "      6      \u001b[36m117.9042\u001b[0m  0.1213\n",
      "      7      \u001b[36m110.7655\u001b[0m  0.1252\n",
      "      8      \u001b[36m104.5721\u001b[0m  0.1515\n",
      "      9       \u001b[36m99.0636\u001b[0m  0.0925\n",
      "     10       \u001b[36m98.5363\u001b[0m  0.0895\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m186.1278\u001b[0m  0.0840\n",
      "      2      \u001b[36m169.2087\u001b[0m  0.1433\n",
      "      3      \u001b[36m155.0511\u001b[0m  0.0875\n",
      "      4      \u001b[36m143.2392\u001b[0m  0.0779\n",
      "      5      \u001b[36m133.3217\u001b[0m  0.0837\n",
      "      6      \u001b[36m124.8755\u001b[0m  0.0901\n",
      "      7      \u001b[36m117.5566\u001b[0m  0.0780\n",
      "      8      \u001b[36m111.1003\u001b[0m  0.0797\n",
      "      9      \u001b[36m105.2931\u001b[0m  0.0864\n",
      "     10      \u001b[36m104.7350\u001b[0m  0.0760\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m217.6824\u001b[0m  0.0750\n",
      "      2      \u001b[36m200.1327\u001b[0m  0.0803\n",
      "      3      \u001b[36m185.3599\u001b[0m  0.0912\n",
      "      4      \u001b[36m172.9131\u001b[0m  0.0871\n",
      "      5      \u001b[36m162.3339\u001b[0m  0.0811\n",
      "      6      \u001b[36m153.1998\u001b[0m  0.0923\n",
      "      7      \u001b[36m145.1511\u001b[0m  0.1007\n",
      "      8      \u001b[36m137.9506\u001b[0m  0.0916\n",
      "      9      \u001b[36m131.3932\u001b[0m  0.1386\n",
      "     10      \u001b[36m130.7569\u001b[0m  0.2114\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m184.0737\u001b[0m  0.1944\n",
      "      2      \u001b[36m166.3615\u001b[0m  0.1977\n",
      "      3      \u001b[36m151.5793\u001b[0m  0.1656\n",
      "      4      \u001b[36m139.3173\u001b[0m  0.1234\n",
      "      5      \u001b[36m129.0605\u001b[0m  0.1070\n",
      "      6      \u001b[36m120.3956\u001b[0m  0.1046\n",
      "      7      \u001b[36m112.9325\u001b[0m  0.1736\n",
      "      8      \u001b[36m106.3974\u001b[0m  0.1904\n",
      "      9      \u001b[36m100.5546\u001b[0m  0.1711\n",
      "     10       \u001b[36m95.2135\u001b[0m  0.1491\n",
      "     11       \u001b[36m90.2609\u001b[0m  0.1033\n",
      "     12       \u001b[36m85.5935\u001b[0m  0.1090\n",
      "     13       \u001b[36m81.1586\u001b[0m  0.1132\n",
      "     14       \u001b[36m76.9215\u001b[0m  0.0953\n",
      "     15       \u001b[36m72.8523\u001b[0m  0.0987\n",
      "     16       \u001b[36m68.9262\u001b[0m  0.1620\n",
      "     17       \u001b[36m68.5382\u001b[0m  0.1496\n",
      "     18       \u001b[36m68.1314\u001b[0m  0.0909\n",
      "     19       \u001b[36m67.7178\u001b[0m  0.0984\n",
      "     20       \u001b[36m67.2924\u001b[0m  0.0821\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m178.6028\u001b[0m  0.0803\n",
      "      2      \u001b[36m161.2679\u001b[0m  0.0819\n",
      "      3      \u001b[36m146.8296\u001b[0m  0.0820\n",
      "      4      \u001b[36m134.8941\u001b[0m  0.1040\n",
      "      5      \u001b[36m124.9903\u001b[0m  0.1022\n",
      "      6      \u001b[36m116.6101\u001b[0m  0.0899\n",
      "      7      \u001b[36m109.3923\u001b[0m  0.0876\n",
      "      8      \u001b[36m103.0262\u001b[0m  0.0848\n",
      "      9       \u001b[36m97.2840\u001b[0m  0.0795\n",
      "     10       \u001b[36m92.0058\u001b[0m  0.0795\n",
      "     11       \u001b[36m87.0840\u001b[0m  0.1103\n",
      "     12       \u001b[36m82.4292\u001b[0m  0.0892\n",
      "     13       \u001b[36m78.0118\u001b[0m  0.2020\n",
      "     14       \u001b[36m73.7954\u001b[0m  0.0897\n",
      "     15       \u001b[36m69.7652\u001b[0m  0.2974\n",
      "     16       \u001b[36m65.9143\u001b[0m  0.3008\n",
      "     17       \u001b[36m65.5299\u001b[0m  0.1122\n",
      "     18       \u001b[36m65.1443\u001b[0m  0.1447\n",
      "     19       \u001b[36m64.7476\u001b[0m  0.1018\n",
      "     20       \u001b[36m64.3320\u001b[0m  0.0885\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m227.1617\u001b[0m  0.0850\n",
      "      2      \u001b[36m209.3227\u001b[0m  0.1801\n",
      "      3      \u001b[36m194.2789\u001b[0m  0.1775\n",
      "      4      \u001b[36m181.6454\u001b[0m  0.1055\n",
      "      5      \u001b[36m170.9590\u001b[0m  0.1429\n",
      "      6      \u001b[36m161.7406\u001b[0m  0.2969\n",
      "      7      \u001b[36m153.6713\u001b[0m  0.1588\n",
      "      8      \u001b[36m146.4679\u001b[0m  0.1373\n",
      "      9      \u001b[36m139.9348\u001b[0m  0.2570\n",
      "     10      \u001b[36m133.8719\u001b[0m  0.1524\n",
      "     11      \u001b[36m128.1697\u001b[0m  0.1857\n",
      "     12      \u001b[36m122.7368\u001b[0m  0.1002\n",
      "     13      \u001b[36m117.5122\u001b[0m  0.0844\n",
      "     14      \u001b[36m112.4561\u001b[0m  0.0871\n",
      "     15      \u001b[36m107.5350\u001b[0m  0.0793\n",
      "     16      \u001b[36m102.7635\u001b[0m  0.0806\n",
      "     17      \u001b[36m102.2983\u001b[0m  0.1809\n",
      "     18      \u001b[36m101.7956\u001b[0m  0.1207\n",
      "     19      \u001b[36m101.3008\u001b[0m  0.1596\n",
      "     20      \u001b[36m100.7945\u001b[0m  0.1215\n",
      "\n",
      " gs.best_score_ = -0.12990906480363723, gs.best_params = {'lr': 0.02, 'max_epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GPWrapper = VariationalGaussianProcessRegressor(\n",
    "    module = GPRegressionModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 40,\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "}\n",
    "gs = GridSearchCV(GPWrapper, params, refit=False, cv=3, scoring='r2',\n",
    "                 return_train_score=False)  # Use a different scoring function maybe?\n",
    "\n",
    "gs.fit(X=train_x, y=train_y)\n",
    "print('\\n gs.best_score_ = {}, gs.best_params = {}'.format(gs.best_score_, gs.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
