{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "Below is the example for a Gaussian Process regression using GpyTorch :class:`.ExactGaussianProcessRegressor`\n",
    "\n",
    "This example shows how to use a GridInterpolationKernel module on an ExactGP model. This regression module is designed for when the inputs of the function you're modeling are one-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpytorch and gpwrapper in a directory above\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from gpwrapper import ExactGaussianProcessRegressor\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training points are in [0,1] every 1/999\n",
    "train_x = Variable(torch.linspace(0, 1, 1000))\n",
    "# Function to model is sin(4*pi*x)\n",
    "# Gaussian noise from N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (4 * math.pi)) + torch.randn(train_x.size()) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the GP model\n",
    "# We use exact GP inference for regression\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5,1e-5])\n",
    "        # Put a grid interpolation kernel over the RBF kernel\n",
    "        self.base_covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.covar_module = GridInterpolationKernel(self.base_covar_module, grid_size=400,\n",
    "                                                            grid_bounds=[(-2, 2)])\n",
    "        # Register kernel lengthscale as parameter\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m27.2577\u001b[0m  0.2383\n",
      "      2       \u001b[36m26.7184\u001b[0m  0.1729\n",
      "      3       \u001b[36m26.1261\u001b[0m  0.1631\n",
      "      4       \u001b[36m25.2871\u001b[0m  0.1618\n",
      "      5       \u001b[36m23.6488\u001b[0m  0.1510\n",
      "      6       \u001b[36m20.7112\u001b[0m  0.1482\n",
      "      7       \u001b[36m16.3476\u001b[0m  0.1803\n",
      "      8       \u001b[36m11.3105\u001b[0m  0.1680\n",
      "      9        \u001b[36m7.1211\u001b[0m  0.1504\n",
      "     10        \u001b[36m4.5721\u001b[0m  0.1448\n",
      "     11        \u001b[36m3.2293\u001b[0m  0.1699\n",
      "     12        \u001b[36m2.4672\u001b[0m  0.1732\n",
      "     13        \u001b[36m2.0025\u001b[0m  0.1544\n",
      "     14        \u001b[36m1.7475\u001b[0m  0.1497\n",
      "     15        \u001b[36m1.6375\u001b[0m  0.1925\n",
      "     16        \u001b[36m1.5932\u001b[0m  0.2015\n",
      "     17        \u001b[36m1.5767\u001b[0m  0.1821\n",
      "     18        \u001b[36m1.5719\u001b[0m  0.2120\n",
      "     19        \u001b[36m1.5689\u001b[0m  0.2278\n",
      "     20        \u001b[36m1.5686\u001b[0m  0.2205\n",
      "     21        \u001b[36m1.5637\u001b[0m  0.1884\n",
      "     22        1.5673  0.1802\n",
      "     23        1.5705  0.1508\n",
      "     24        1.5706  0.1525\n",
      "     25        1.5708  0.1553\n",
      "     26        1.5749  0.1571\n",
      "     27        1.5708  0.1575\n",
      "     28        1.5680  0.1546\n",
      "     29        1.5763  0.1567\n",
      "     30        1.5666  0.1539\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Wrap the model into our GP Wrapper\n",
    "GP = ExactGaussianProcessRegressor(\n",
    "    module = GPRegressionModel,\n",
    "    train_split = None,\n",
    "    max_epochs = 30,\n",
    ")\n",
    "\n",
    "# Step 3: Find optimal model hyperparameters\n",
    "GP.fit(X=train_x, y=train_y)\n",
    "\n",
    "# Step 4: Prediction\n",
    "test_x = Variable(torch.linspace(0, 1, 51))\n",
    "observed_pred = GP.predict_proba(X=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (*) Step 5: Plotting\n",
    "# Define plotting function\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # Get lower and upper predictive bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot the training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Plot confidence bounds as lightly shaded region\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn Pipeline\n",
    "Same as skorch, our wrapper provides an sklearn-compatible interface, so it is possible to put it into an sklearn Pipeline. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8303\u001b[0m  0.1735\n",
      "      2        \u001b[36m1.6462\u001b[0m  0.2344\n",
      "      3        \u001b[36m1.5930\u001b[0m  0.2246\n",
      "      4        \u001b[36m1.5753\u001b[0m  0.1916\n",
      "      5        \u001b[36m1.5712\u001b[0m  0.1525\n",
      "      6        \u001b[36m1.5662\u001b[0m  0.2004\n",
      "      7        1.5673  0.1848\n",
      "      8        1.5705  0.1492\n",
      "      9        1.5694  0.1519\n",
      "     10        1.5767  0.1480\n",
      "     11        1.5716  0.1777\n",
      "     12        1.5698  0.1662\n",
      "     13        1.5703  0.1386\n",
      "     14        1.5671  0.1514\n",
      "     15        1.5678  0.1460\n",
      "     16        1.5690  0.1438\n",
      "     17        1.5686  0.1376\n",
      "     18        1.5704  0.1443\n",
      "     19        \u001b[36m1.5657\u001b[0m  0.1441\n",
      "     20        1.5666  0.1393\n",
      "     21        \u001b[36m1.5646\u001b[0m  0.1424\n",
      "     22        1.5660  0.1510\n",
      "     23        \u001b[36m1.5635\u001b[0m  0.1433\n",
      "     24        \u001b[36m1.5611\u001b[0m  0.1449\n",
      "     25        1.5645  0.1472\n",
      "     26        1.5619  0.1525\n",
      "     27        1.5624  0.1447\n",
      "     28        1.5616  0.1512\n",
      "     29        1.5662  0.1494\n",
      "     30        \u001b[36m1.5602\u001b[0m  0.1499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('GP', <class 'gpwrapper.ExactGaussianProcessRegressor'>[initialized](\n",
       "  module_=GPRegressionModel(\n",
       "    (likelihood): GaussianLikelihood()\n",
       "    (mean_module): ConstantMean()\n",
       "    (base_covar_module): RBFKernel()\n",
       "    (covar_module): GridInterpolationKernel(\n",
       "      (base_kernel_module): RBFKernel()\n",
       "    )\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('GP', GP),\n",
    "])\n",
    "\n",
    "pipe.fit(X=train_x.unsqueeze(-1), y=train_y) ## modify grid_bound above from (0,1) to (-2,2) to get it work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "Same as skorch, another advantage of our wrapper is that you can perform an sklearn GridSearchCV or RandomizedSearchCV in Gpytorch to find optimal hyperparameters. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6868\u001b[0m  0.1194\n",
      "      2       \u001b[36m16.5500\u001b[0m  0.1165\n",
      "      3       \u001b[36m16.4011\u001b[0m  0.1209\n",
      "      4       \u001b[36m16.2468\u001b[0m  0.1242\n",
      "      5       \u001b[36m16.1061\u001b[0m  0.1639\n",
      "      6       \u001b[36m15.9526\u001b[0m  0.1280\n",
      "      7       \u001b[36m15.8088\u001b[0m  0.1194\n",
      "      8       \u001b[36m15.6545\u001b[0m  0.1157\n",
      "      9       \u001b[36m15.5064\u001b[0m  0.1164\n",
      "     10       \u001b[36m15.3383\u001b[0m  0.1225\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.2662\u001b[0m  0.0964\n",
      "      2       \u001b[36m19.2568\u001b[0m  0.1471\n",
      "      3       \u001b[36m19.2386\u001b[0m  0.1463\n",
      "      4       \u001b[36m19.2206\u001b[0m  0.1479\n",
      "      5       \u001b[36m19.2063\u001b[0m  0.1567\n",
      "      6       \u001b[36m19.1972\u001b[0m  0.1672\n",
      "      7       \u001b[36m19.1817\u001b[0m  0.1663\n",
      "      8       \u001b[36m19.1664\u001b[0m  0.1660\n",
      "      9       \u001b[36m19.1521\u001b[0m  0.1286\n",
      "     10       \u001b[36m19.1275\u001b[0m  0.1245\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6585\u001b[0m  0.0872\n",
      "      2       \u001b[36m16.5400\u001b[0m  0.1209\n",
      "      3       \u001b[36m16.4134\u001b[0m  0.1270\n",
      "      4       \u001b[36m16.2762\u001b[0m  0.1233\n",
      "      5       \u001b[36m16.1524\u001b[0m  0.1233\n",
      "      6       \u001b[36m16.0218\u001b[0m  0.1170\n",
      "      7       \u001b[36m15.8952\u001b[0m  0.1283\n",
      "      8       \u001b[36m15.7526\u001b[0m  0.1194\n",
      "      9       \u001b[36m15.6328\u001b[0m  0.1164\n",
      "     10       \u001b[36m15.4984\u001b[0m  0.1189\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6868\u001b[0m  0.0866\n",
      "      2       \u001b[36m16.5500\u001b[0m  0.1308\n",
      "      3       \u001b[36m16.3992\u001b[0m  0.1160\n",
      "      4       \u001b[36m16.2561\u001b[0m  0.1320\n",
      "      5       \u001b[36m16.1023\u001b[0m  0.1132\n",
      "      6       \u001b[36m15.9529\u001b[0m  0.1218\n",
      "      7       \u001b[36m15.8112\u001b[0m  0.1193\n",
      "      8       \u001b[36m15.6591\u001b[0m  0.1180\n",
      "      9       \u001b[36m15.5040\u001b[0m  0.1114\n",
      "     10       \u001b[36m15.3380\u001b[0m  0.1133\n",
      "     11       \u001b[36m15.1931\u001b[0m  0.1210\n",
      "     12       \u001b[36m15.0373\u001b[0m  0.1285\n",
      "     13       \u001b[36m14.8717\u001b[0m  0.1209\n",
      "     14       \u001b[36m14.7187\u001b[0m  0.1178\n",
      "     15       \u001b[36m14.5753\u001b[0m  0.1252\n",
      "     16       \u001b[36m14.4175\u001b[0m  0.1552\n",
      "     17       \u001b[36m14.2565\u001b[0m  0.1880\n",
      "     18       \u001b[36m14.1105\u001b[0m  0.2116\n",
      "     19       \u001b[36m13.9562\u001b[0m  0.1317\n",
      "     20       \u001b[36m13.8090\u001b[0m  0.1774\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.2662\u001b[0m  0.1078\n",
      "      2       \u001b[36m19.2568\u001b[0m  0.1308\n",
      "      3       \u001b[36m19.2386\u001b[0m  0.2049\n",
      "      4       \u001b[36m19.2216\u001b[0m  0.1574\n",
      "      5       \u001b[36m19.2048\u001b[0m  0.2031\n",
      "      6       \u001b[36m19.1873\u001b[0m  0.2186\n",
      "      7       \u001b[36m19.1806\u001b[0m  0.1865\n",
      "      8       \u001b[36m19.1655\u001b[0m  0.1340\n",
      "      9       \u001b[36m19.1576\u001b[0m  0.1379\n",
      "     10       \u001b[36m19.1302\u001b[0m  0.1271\n",
      "     11       \u001b[36m19.1248\u001b[0m  0.1474\n",
      "     12       \u001b[36m19.1007\u001b[0m  0.2041\n",
      "     13       \u001b[36m19.0894\u001b[0m  0.1841\n",
      "     14       \u001b[36m19.0714\u001b[0m  0.1766\n",
      "     15       \u001b[36m19.0480\u001b[0m  0.1787\n",
      "     16       \u001b[36m19.0345\u001b[0m  0.1289\n",
      "     17       \u001b[36m19.0167\u001b[0m  0.1286\n",
      "     18       \u001b[36m18.9952\u001b[0m  0.1298\n",
      "     19       \u001b[36m18.9690\u001b[0m  0.2083\n",
      "     20       \u001b[36m18.9460\u001b[0m  0.1761\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6585\u001b[0m  0.0869\n",
      "      2       \u001b[36m16.5400\u001b[0m  0.1264\n",
      "      3       \u001b[36m16.4059\u001b[0m  0.1256\n",
      "      4       \u001b[36m16.2924\u001b[0m  0.1247\n",
      "      5       \u001b[36m16.1587\u001b[0m  0.2304\n",
      "      6       \u001b[36m16.0245\u001b[0m  0.2227\n",
      "      7       \u001b[36m15.8838\u001b[0m  0.1912\n",
      "      8       \u001b[36m15.7544\u001b[0m  0.2057\n",
      "      9       \u001b[36m15.6278\u001b[0m  0.1962\n",
      "     10       \u001b[36m15.4968\u001b[0m  0.1799\n",
      "     11       \u001b[36m15.3493\u001b[0m  0.3537\n",
      "     12       \u001b[36m15.2314\u001b[0m  0.5107\n",
      "     13       \u001b[36m15.0845\u001b[0m  0.4917\n",
      "     14       \u001b[36m14.9411\u001b[0m  0.3586\n",
      "     15       \u001b[36m14.8149\u001b[0m  0.2081\n",
      "     16       \u001b[36m14.6689\u001b[0m  0.1890\n",
      "     17       \u001b[36m14.5369\u001b[0m  0.1731\n",
      "     18       \u001b[36m14.3992\u001b[0m  0.1353\n",
      "     19       \u001b[36m14.2761\u001b[0m  0.1310\n",
      "     20       \u001b[36m14.1347\u001b[0m  0.1283\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6868\u001b[0m  0.2251\n",
      "      2       \u001b[36m16.4066\u001b[0m  0.1603\n",
      "      3       \u001b[36m16.1076\u001b[0m  0.1454\n",
      "      4       \u001b[36m15.7988\u001b[0m  0.1738\n",
      "      5       \u001b[36m15.5079\u001b[0m  0.1614\n",
      "      6       \u001b[36m15.1916\u001b[0m  0.1300\n",
      "      7       \u001b[36m14.8870\u001b[0m  0.1224\n",
      "      8       \u001b[36m14.5568\u001b[0m  0.1255\n",
      "      9       \u001b[36m14.2665\u001b[0m  0.1250\n",
      "     10       \u001b[36m13.9478\u001b[0m  0.1322\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.2662\u001b[0m  0.0918\n",
      "      2       \u001b[36m19.2416\u001b[0m  0.1329\n",
      "      3       \u001b[36m19.2025\u001b[0m  0.1246\n",
      "      4       \u001b[36m19.1922\u001b[0m  0.1237\n",
      "      5       \u001b[36m19.1537\u001b[0m  0.1190\n",
      "      6       \u001b[36m19.1201\u001b[0m  0.1227\n",
      "      7       \u001b[36m19.0860\u001b[0m  0.1293\n",
      "      8       \u001b[36m19.0603\u001b[0m  0.1600\n",
      "      9       \u001b[36m19.0179\u001b[0m  0.1363\n",
      "     10       \u001b[36m18.9696\u001b[0m  0.1483\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6585\u001b[0m  0.1039\n",
      "      2       \u001b[36m16.4151\u001b[0m  0.1207\n",
      "      3       \u001b[36m16.1512\u001b[0m  0.1208\n",
      "      4       \u001b[36m15.8893\u001b[0m  0.1260\n",
      "      5       \u001b[36m15.6299\u001b[0m  0.1931\n",
      "      6       \u001b[36m15.3607\u001b[0m  0.1331\n",
      "      7       \u001b[36m15.0890\u001b[0m  0.1425\n",
      "      8       \u001b[36m14.8108\u001b[0m  0.1429\n",
      "      9       \u001b[36m14.5462\u001b[0m  0.1347\n",
      "     10       \u001b[36m14.2861\u001b[0m  0.1257\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6868\u001b[0m  0.0949\n",
      "      2       \u001b[36m16.4066\u001b[0m  0.1190\n",
      "      3       \u001b[36m16.1111\u001b[0m  0.1173\n",
      "      4       \u001b[36m15.7988\u001b[0m  0.1219\n",
      "      5       \u001b[36m15.5090\u001b[0m  0.1195\n",
      "      6       \u001b[36m15.1875\u001b[0m  0.1177\n",
      "      7       \u001b[36m14.8770\u001b[0m  0.1165\n",
      "      8       \u001b[36m14.5598\u001b[0m  0.1194\n",
      "      9       \u001b[36m14.2565\u001b[0m  0.1280\n",
      "     10       \u001b[36m13.9630\u001b[0m  0.1336\n",
      "     11       \u001b[36m13.6612\u001b[0m  0.1275\n",
      "     12       \u001b[36m13.3702\u001b[0m  0.1276\n",
      "     13       \u001b[36m13.0862\u001b[0m  0.1184\n",
      "     14       \u001b[36m12.8066\u001b[0m  0.1472\n",
      "     15       \u001b[36m12.5275\u001b[0m  0.1478\n",
      "     16       \u001b[36m12.2677\u001b[0m  0.1498\n",
      "     17       \u001b[36m12.0049\u001b[0m  0.1571\n",
      "     18       \u001b[36m11.7358\u001b[0m  0.2495\n",
      "     19       \u001b[36m11.4775\u001b[0m  0.2019\n",
      "     20       \u001b[36m11.2145\u001b[0m  0.1693\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.2662\u001b[0m  0.0935\n",
      "      2       \u001b[36m19.2416\u001b[0m  0.1218\n",
      "      3       \u001b[36m19.2101\u001b[0m  0.1241\n",
      "      4       \u001b[36m19.1847\u001b[0m  0.1255\n",
      "      5       \u001b[36m19.1539\u001b[0m  0.1284\n",
      "      6       \u001b[36m19.1214\u001b[0m  0.1318\n",
      "      7       \u001b[36m19.0859\u001b[0m  0.1251\n",
      "      8       \u001b[36m19.0570\u001b[0m  0.1367\n",
      "      9       \u001b[36m19.0156\u001b[0m  0.1228\n",
      "     10       \u001b[36m18.9876\u001b[0m  0.1328\n",
      "     11       \u001b[36m18.9246\u001b[0m  0.1248\n",
      "     12       \u001b[36m18.8659\u001b[0m  0.1326\n",
      "     13       \u001b[36m18.8010\u001b[0m  0.1206\n",
      "     14       \u001b[36m18.7233\u001b[0m  0.1345\n",
      "     15       \u001b[36m18.6360\u001b[0m  0.1280\n",
      "     16       \u001b[36m18.5290\u001b[0m  0.1220\n",
      "     17       \u001b[36m18.3881\u001b[0m  0.1257\n",
      "     18       \u001b[36m18.2344\u001b[0m  0.1188\n",
      "     19       \u001b[36m18.0403\u001b[0m  0.1202\n",
      "     20       \u001b[36m17.7986\u001b[0m  0.1281\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m16.6585\u001b[0m  0.0937\n",
      "      2       \u001b[36m16.4151\u001b[0m  0.1136\n",
      "      3       \u001b[36m16.1448\u001b[0m  0.1096\n",
      "      4       \u001b[36m15.8875\u001b[0m  0.1229\n",
      "      5       \u001b[36m15.6233\u001b[0m  0.1251\n",
      "      6       \u001b[36m15.3605\u001b[0m  0.1188\n",
      "      7       \u001b[36m15.0901\u001b[0m  0.1196\n",
      "      8       \u001b[36m14.8106\u001b[0m  0.1245\n",
      "      9       \u001b[36m14.5382\u001b[0m  0.1216\n",
      "     10       \u001b[36m14.2897\u001b[0m  0.1241\n",
      "     11       \u001b[36m14.0229\u001b[0m  0.1204\n",
      "     12       \u001b[36m13.7521\u001b[0m  0.1321\n",
      "     13       \u001b[36m13.4957\u001b[0m  0.1178\n",
      "     14       \u001b[36m13.2441\u001b[0m  0.1237\n",
      "     15       \u001b[36m12.9849\u001b[0m  0.1181\n",
      "     16       \u001b[36m12.7336\u001b[0m  0.1168\n",
      "     17       \u001b[36m12.4888\u001b[0m  0.1195\n",
      "     18       \u001b[36m12.2406\u001b[0m  0.1245\n",
      "     19       \u001b[36m11.9759\u001b[0m  0.1162\n",
      "     20       \u001b[36m11.7133\u001b[0m  0.1160\n",
      "\n",
      " gs.best_score_ = -60.648343806482934, gs.best_params = {'lr': 0.02, 'max_epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "}\n",
    "gs = GridSearchCV(GP, params, refit=False, cv=3, scoring='r2',\n",
    "                 return_train_score=False)  # Use a different scoring function maybe?\n",
    "\n",
    "gs.fit(X=train_x, y=train_y)\n",
    "print('\\n gs.best_score_ = {}, gs.best_params = {}'.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Need to comment out **line 157 - 161** of `.../anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/__init__.py`\n",
    "```\n",
    "if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n",
    "                           indices.dtype.kind == 'i'):\n",
    "    # This is often substantially faster than X[indices]\n",
    "    return X.take(indices, axis=0)\n",
    "else:\n",
    "```\n",
    "Otherwise an error would occur saying\n",
    "`argument 'index' (position 1) must be Tensor, not numpy.ndarray`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
