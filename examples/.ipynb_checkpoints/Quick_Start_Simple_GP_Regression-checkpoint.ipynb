{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used source code for skorch (https://skorch.readthedocs.io) to build our GPyTorch Wrapper\n",
    "\n",
    "## Four steps to work with our GPyTorch Wrapper:\n",
    "<b>1. Define a GP model </b>\n",
    "\n",
    "<b>2. wrap the model into one of the following GPwrappers:</b>\n",
    "    - ExactGaussianProcess (Use criterion = gpytorch.mlls.ExactMarginalLogLikelihood as default)\n",
    "         - ExactGaussianProcessRegressor  (Use likelihood = GaussianLikelihood as default)\n",
    "    - VariationalGaussianProcess (use criterion = gpytorch.mlls.VariationalMarginalLogLikelihood as default)\n",
    "         - VariationalGaussianProcessRegressor (Use likelihood = GaussianLikelihood as default)\n",
    "         - VariationalGaussianProcessClassifier (Use likelihood = BernoulliLikelihood as default)\n",
    "<b>3. fit(x_train, y_train):</b>  # Find optimal model hyperparameters with default optimizer torch.optim.Adam\n",
    "\n",
    "<b>4. predict_proba(x_test):</b>  # Return a GaussianRandomVariable as the predictive outputs for x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "Below is the example for a simple Gaussian Process regression using GpyTorch :class:`.ExactGaussianProcessRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpytorch and gpwrapper in a directory above\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from gpwrapper import ExactGaussianProcessRegressor\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch.autograd import Variable\n",
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = Variable(torch.linspace(0, 1, 11))\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the GP model\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m18.1162\u001b[0m  0.0792\n",
      "      2       \u001b[36m16.5294\u001b[0m  0.0592\n",
      "      3       \u001b[36m14.4397\u001b[0m  0.0095\n",
      "      4       \u001b[36m11.9666\u001b[0m  0.0144\n",
      "      5        \u001b[36m9.4068\u001b[0m  0.0183\n",
      "      6        \u001b[36m7.1224\u001b[0m  0.0155\n",
      "      7        \u001b[36m5.3722\u001b[0m  0.0152\n",
      "      8        \u001b[36m4.2027\u001b[0m  0.0152\n",
      "      9        \u001b[36m3.5067\u001b[0m  0.0152\n",
      "     10        \u001b[36m3.1252\u001b[0m  0.0145\n",
      "     11        \u001b[36m2.9252\u001b[0m  0.0112\n",
      "     12        \u001b[36m2.8232\u001b[0m  0.0143\n",
      "     13        \u001b[36m2.7746\u001b[0m  0.0130\n",
      "     14        \u001b[36m2.7508\u001b[0m  0.0123\n",
      "     15        \u001b[36m2.6336\u001b[0m  0.0151\n",
      "     16        2.6384  0.0130\n",
      "     17        \u001b[36m2.5950\u001b[0m  0.0116\n",
      "     18        2.7075  0.0084\n",
      "     19        \u001b[36m2.5385\u001b[0m  0.0161\n",
      "     20        \u001b[36m2.5084\u001b[0m  0.0187\n",
      "     21        \u001b[36m2.4774\u001b[0m  0.0173\n",
      "     22        2.5373  0.0231\n",
      "     23        \u001b[36m2.3017\u001b[0m  0.0136\n",
      "     24        2.4373  0.0173\n",
      "     25        2.3779  0.0174\n",
      "     26        \u001b[36m2.2113\u001b[0m  0.0179\n",
      "     27        2.2468  0.0176\n",
      "     28        \u001b[36m2.1506\u001b[0m  0.0109\n",
      "     29        \u001b[36m1.9888\u001b[0m  0.0172\n",
      "     30        \u001b[36m1.8875\u001b[0m  0.0132\n",
      "     31        2.0765  0.0218\n",
      "     32        2.0026  0.0135\n",
      "     33        \u001b[36m1.7449\u001b[0m  0.0092\n",
      "     34        1.8667  0.0140\n",
      "     35        1.7647  0.0167\n",
      "     36        \u001b[36m1.7037\u001b[0m  0.0198\n",
      "     37        1.8841  0.0099\n",
      "     38        1.7585  0.0166\n",
      "     39        1.7642  0.0127\n",
      "     40        \u001b[36m1.5531\u001b[0m  0.0143\n",
      "     41        \u001b[36m1.4506\u001b[0m  0.0146\n",
      "     42        1.6734  0.0177\n",
      "     43        1.6943  0.0088\n",
      "     44        1.6428  0.0107\n",
      "     45        1.8019  0.0128\n",
      "     46        1.7576  0.0119\n",
      "     47        1.6244  0.0184\n",
      "     48        1.6876  0.0204\n",
      "     49        1.7669  0.0172\n",
      "     50        1.9996  0.0127\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Wrap the model into our GP Wrapper\n",
    "GP = ExactGaussianProcessRegressor(\n",
    "    module = ExactGPModel,\n",
    "    train_split = None,\n",
    ")\n",
    "\n",
    "# Step 3: Find optimal model hyperparameters\n",
    "GP.fit(X=train_x, y=train_y)\n",
    "\n",
    "# Step 4: Prediction\n",
    "test_x = Variable(torch.linspace(0, 1, 51))\n",
    "observed_pred = GP.predict_proba(X=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (*) Step 5: Plotting\n",
    "# Define plotting function\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # Get lower and upper predictive bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot the training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Plot confidence bounds as lightly shaded region\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn Pipeline\n",
    "Same as skorch, our wrapper provides an sklearn-compatible interface, so it is possible to put it into an sklearn Pipeline. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6198\u001b[0m  0.0094\n",
      "      2        \u001b[36m2.6083\u001b[0m  0.0148\n",
      "      3        \u001b[36m2.5034\u001b[0m  0.0268\n",
      "      4        2.5332  0.0188\n",
      "      5        \u001b[36m2.3453\u001b[0m  0.0144\n",
      "      6        \u001b[36m2.1488\u001b[0m  0.0181\n",
      "      7        \u001b[36m2.0856\u001b[0m  0.0139\n",
      "      8        \u001b[36m1.8338\u001b[0m  0.0125\n",
      "      9        \u001b[36m1.6801\u001b[0m  0.0106\n",
      "     10        \u001b[36m1.6217\u001b[0m  0.0114\n",
      "     11        1.9302  0.0140\n",
      "     12        1.8152  0.0147\n",
      "     13        1.7589  0.0127\n",
      "     14        2.0150  0.0109\n",
      "     15        2.1317  0.0139\n",
      "     16        2.2061  0.0128\n",
      "     17        2.1506  0.0110\n",
      "     18        2.1678  0.0112\n",
      "     19        2.1327  0.0127\n",
      "     20        2.2624  0.0123\n",
      "     21        2.2076  0.0127\n",
      "     22        2.3043  0.0102\n",
      "     23        2.2372  0.0107\n",
      "     24        2.2588  0.0095\n",
      "     25        2.2315  0.0137\n",
      "     26        2.0421  0.0146\n",
      "     27        2.2243  0.0143\n",
      "     28        2.1377  0.0131\n",
      "     29        2.0736  0.0120\n",
      "     30        2.1531  0.0150\n",
      "     31        2.0016  0.0111\n",
      "     32        1.8630  0.0138\n",
      "     33        1.8369  0.0152\n",
      "     34        1.6792  0.0158\n",
      "     35        1.8374  0.0122\n",
      "     36        1.6727  0.0161\n",
      "     37        \u001b[36m1.6173\u001b[0m  0.0114\n",
      "     38        1.7154  0.0163\n",
      "     39        1.6818  0.0132\n",
      "     40        1.7423  0.0082\n",
      "     41        1.7394  0.0113\n",
      "     42        1.6631  0.0148\n",
      "     43        1.6722  0.0098\n",
      "     44        \u001b[36m1.5623\u001b[0m  0.0153\n",
      "     45        1.6099  0.0122\n",
      "     46        1.6794  0.0113\n",
      "     47        1.8244  0.0153\n",
      "     48        1.6185  0.0128\n",
      "     49        1.6626  0.0129\n",
      "     50        1.6868  0.0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('GP', <class 'gpwrapper.ExactGaussianProcessRegressor'>[initialized](\n",
       "  module_=ExactGPModel(\n",
       "    (likelihood): GaussianLikelihood()\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): RBFKernel()\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('GP', GP),\n",
    "])\n",
    "\n",
    "pipe.fit(X=train_x.unsqueeze(-1), y=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "Same as skorch, another advantage of our wrapper is that you can perform an sklearn GridSearchCV or RandomizedSearchCV in Gpytorch to find optimal hyperparameters. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m13.3963\u001b[0m  0.0057\n",
      "      2       \u001b[36m13.2091\u001b[0m  0.0092\n",
      "      3       \u001b[36m13.0196\u001b[0m  0.0177\n",
      "      4       \u001b[36m12.8300\u001b[0m  0.0143\n",
      "      5       \u001b[36m12.6380\u001b[0m  0.0121\n",
      "      6       \u001b[36m12.4456\u001b[0m  0.0096\n",
      "      7       \u001b[36m12.2508\u001b[0m  0.0119\n",
      "      8       \u001b[36m12.0566\u001b[0m  0.0115\n",
      "      9       \u001b[36m11.8613\u001b[0m  0.0138\n",
      "     10       \u001b[36m11.6653\u001b[0m  0.0070\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.1313\u001b[0m  0.0097\n",
      "      2       \u001b[36m19.0124\u001b[0m  0.0097\n",
      "      3       \u001b[36m18.8891\u001b[0m  0.0120\n",
      "      4       \u001b[36m18.7615\u001b[0m  0.0139\n",
      "      5       \u001b[36m18.6294\u001b[0m  0.0113\n",
      "      6       \u001b[36m18.4924\u001b[0m  0.0116\n",
      "      7       \u001b[36m18.3504\u001b[0m  0.0135\n",
      "      8       \u001b[36m18.2032\u001b[0m  0.0113\n",
      "      9       \u001b[36m18.0507\u001b[0m  0.0107\n",
      "     10       \u001b[36m17.8927\u001b[0m  0.0132\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m12.3479\u001b[0m  0.0069\n",
      "      2       \u001b[36m12.2045\u001b[0m  0.0090\n",
      "      3       \u001b[36m12.0610\u001b[0m  0.0080\n",
      "      4       \u001b[36m11.9175\u001b[0m  0.0095\n",
      "      5       \u001b[36m11.7764\u001b[0m  0.0113\n",
      "      6       \u001b[36m11.6347\u001b[0m  0.0124\n",
      "      7       \u001b[36m11.4933\u001b[0m  0.0122\n",
      "      8       \u001b[36m11.3541\u001b[0m  0.0097\n",
      "      9       \u001b[36m11.2163\u001b[0m  0.0213\n",
      "     10       \u001b[36m11.0783\u001b[0m  0.0323\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m13.3968\u001b[0m  0.0210\n",
      "      2       \u001b[36m13.2090\u001b[0m  0.0163\n",
      "      3       \u001b[36m13.0201\u001b[0m  0.0205\n",
      "      4       \u001b[36m12.8299\u001b[0m  0.0155\n",
      "      5       \u001b[36m12.6384\u001b[0m  0.0166\n",
      "      6       \u001b[36m12.4460\u001b[0m  0.0170\n",
      "      7       \u001b[36m12.2524\u001b[0m  0.0160\n",
      "      8       \u001b[36m12.0581\u001b[0m  0.0148\n",
      "      9       \u001b[36m11.8634\u001b[0m  0.0158\n",
      "     10       \u001b[36m11.6689\u001b[0m  0.0153\n",
      "     11       \u001b[36m11.4738\u001b[0m  0.0173\n",
      "     12       \u001b[36m11.2786\u001b[0m  0.0144\n",
      "     13       \u001b[36m11.0837\u001b[0m  0.0218\n",
      "     14       \u001b[36m10.8894\u001b[0m  0.0161\n",
      "     15       \u001b[36m10.6942\u001b[0m  0.0142\n",
      "     16       \u001b[36m10.5004\u001b[0m  0.0136\n",
      "     17       \u001b[36m10.3070\u001b[0m  0.0154\n",
      "     18       \u001b[36m10.1149\u001b[0m  0.0164\n",
      "     19        \u001b[36m9.9241\u001b[0m  0.0161\n",
      "     20        \u001b[36m9.7346\u001b[0m  0.0183\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.1313\u001b[0m  0.0157\n",
      "      2       \u001b[36m19.0124\u001b[0m  0.0105\n",
      "      3       \u001b[36m18.8892\u001b[0m  0.0177\n",
      "      4       \u001b[36m18.7619\u001b[0m  0.0159\n",
      "      5       \u001b[36m18.6297\u001b[0m  0.0222\n",
      "      6       \u001b[36m18.4927\u001b[0m  0.0241\n",
      "      7       \u001b[36m18.3509\u001b[0m  0.0268\n",
      "      8       \u001b[36m18.2042\u001b[0m  0.0237\n",
      "      9       \u001b[36m18.0516\u001b[0m  0.0207\n",
      "     10       \u001b[36m17.8932\u001b[0m  0.0174\n",
      "     11       \u001b[36m17.7294\u001b[0m  0.0304\n",
      "     12       \u001b[36m17.5595\u001b[0m  0.0188\n",
      "     13       \u001b[36m17.3834\u001b[0m  0.0211\n",
      "     14       \u001b[36m17.2011\u001b[0m  0.0171\n",
      "     15       \u001b[36m17.0120\u001b[0m  0.0212\n",
      "     16       \u001b[36m16.8163\u001b[0m  0.0375\n",
      "     17       \u001b[36m16.6138\u001b[0m  0.0233\n",
      "     18       \u001b[36m16.4046\u001b[0m  0.0200\n",
      "     19       \u001b[36m16.1883\u001b[0m  0.0302\n",
      "     20       \u001b[36m15.9650\u001b[0m  0.0131\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m12.3475\u001b[0m  0.0103\n",
      "      2       \u001b[36m12.2047\u001b[0m  0.0116\n",
      "      3       \u001b[36m12.0615\u001b[0m  0.0173\n",
      "      4       \u001b[36m11.9185\u001b[0m  0.0206\n",
      "      5       \u001b[36m11.7769\u001b[0m  0.0175\n",
      "      6       \u001b[36m11.6350\u001b[0m  0.0194\n",
      "      7       \u001b[36m11.4948\u001b[0m  0.0188\n",
      "      8       \u001b[36m11.3562\u001b[0m  0.0167\n",
      "      9       \u001b[36m11.2163\u001b[0m  0.0173\n",
      "     10       \u001b[36m11.0820\u001b[0m  0.0183\n",
      "     11       \u001b[36m10.9434\u001b[0m  0.0132\n",
      "     12       \u001b[36m10.8092\u001b[0m  0.0179\n",
      "     13       \u001b[36m10.6742\u001b[0m  0.0161\n",
      "     14       \u001b[36m10.5439\u001b[0m  0.0142\n",
      "     15       \u001b[36m10.4124\u001b[0m  0.0104\n",
      "     16       \u001b[36m10.2812\u001b[0m  0.0169\n",
      "     17       \u001b[36m10.1564\u001b[0m  0.0144\n",
      "     18       \u001b[36m10.0296\u001b[0m  0.0147\n",
      "     19        \u001b[36m9.9045\u001b[0m  0.0128\n",
      "     20        \u001b[36m9.7828\u001b[0m  0.0155\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m13.3963\u001b[0m  0.0082\n",
      "      2       \u001b[36m13.0196\u001b[0m  0.0106\n",
      "      3       \u001b[36m12.6380\u001b[0m  0.0185\n",
      "      4       \u001b[36m12.2522\u001b[0m  0.0223\n",
      "      5       \u001b[36m11.8634\u001b[0m  0.0229\n",
      "      6       \u001b[36m11.4735\u001b[0m  0.0275\n",
      "      7       \u001b[36m11.0822\u001b[0m  0.0191\n",
      "      8       \u001b[36m10.6920\u001b[0m  0.0171\n",
      "      9       \u001b[36m10.3057\u001b[0m  0.0178\n",
      "     10        \u001b[36m9.9213\u001b[0m  0.0204\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.1313\u001b[0m  0.0058\n",
      "      2       \u001b[36m18.8895\u001b[0m  0.0102\n",
      "      3       \u001b[36m18.6300\u001b[0m  0.0188\n",
      "      4       \u001b[36m18.3523\u001b[0m  0.0147\n",
      "      5       \u001b[36m18.0550\u001b[0m  0.0218\n",
      "      6       \u001b[36m17.7372\u001b[0m  0.0244\n",
      "      7       \u001b[36m17.3981\u001b[0m  0.0211\n",
      "      8       \u001b[36m17.0362\u001b[0m  0.0144\n",
      "      9       \u001b[36m16.6510\u001b[0m  0.0210\n",
      "     10       \u001b[36m16.2426\u001b[0m  0.0186\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m12.3470\u001b[0m  0.0138\n",
      "      2       \u001b[36m12.0607\u001b[0m  0.0132\n",
      "      3       \u001b[36m11.7751\u001b[0m  0.0176\n",
      "      4       \u001b[36m11.4946\u001b[0m  0.0166\n",
      "      5       \u001b[36m11.2151\u001b[0m  0.0125\n",
      "      6       \u001b[36m10.9401\u001b[0m  0.0186\n",
      "      7       \u001b[36m10.6692\u001b[0m  0.0314\n",
      "      8       \u001b[36m10.4052\u001b[0m  0.0141\n",
      "      9       \u001b[36m10.1453\u001b[0m  0.0159\n",
      "     10        \u001b[36m9.8894\u001b[0m  0.0184\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m13.3964\u001b[0m  0.0185\n",
      "      2       \u001b[36m13.0201\u001b[0m  0.0128\n",
      "      3       \u001b[36m12.6385\u001b[0m  0.0231\n",
      "      4       \u001b[36m12.2526\u001b[0m  0.0096\n",
      "      5       \u001b[36m11.8639\u001b[0m  0.0115\n",
      "      6       \u001b[36m11.4743\u001b[0m  0.0161\n",
      "      7       \u001b[36m11.0834\u001b[0m  0.0162\n",
      "      8       \u001b[36m10.6936\u001b[0m  0.0152\n",
      "      9       \u001b[36m10.3057\u001b[0m  0.0210\n",
      "     10        \u001b[36m9.9223\u001b[0m  0.0100\n",
      "     11        \u001b[36m9.5432\u001b[0m  0.0126\n",
      "     12        \u001b[36m9.1707\u001b[0m  0.0093\n",
      "     13        \u001b[36m8.8061\u001b[0m  0.0105\n",
      "     14        \u001b[36m8.4507\u001b[0m  0.0093\n",
      "     15        \u001b[36m8.1030\u001b[0m  0.0086\n",
      "     16        \u001b[36m7.7678\u001b[0m  0.0122\n",
      "     17        \u001b[36m7.4469\u001b[0m  0.0127\n",
      "     18        \u001b[36m7.1328\u001b[0m  0.0119\n",
      "     19        \u001b[36m6.8343\u001b[0m  0.0185\n",
      "     20        \u001b[36m6.5521\u001b[0m  0.0086\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m19.1313\u001b[0m  0.0073\n",
      "      2       \u001b[36m18.8895\u001b[0m  0.0176\n",
      "      3       \u001b[36m18.6300\u001b[0m  0.0300\n",
      "      4       \u001b[36m18.3526\u001b[0m  0.0346\n",
      "      5       \u001b[36m18.0555\u001b[0m  0.0244\n",
      "      6       \u001b[36m17.7377\u001b[0m  0.0126\n",
      "      7       \u001b[36m17.3983\u001b[0m  0.0138\n",
      "      8       \u001b[36m17.0366\u001b[0m  0.0174\n",
      "      9       \u001b[36m16.6516\u001b[0m  0.0164\n",
      "     10       \u001b[36m16.2431\u001b[0m  0.0208\n",
      "     11       \u001b[36m15.8108\u001b[0m  0.0173\n",
      "     12       \u001b[36m15.3557\u001b[0m  0.0176\n",
      "     13       \u001b[36m14.8771\u001b[0m  0.0120\n",
      "     14       \u001b[36m14.3772\u001b[0m  0.0077\n",
      "     15       \u001b[36m13.8575\u001b[0m  0.0166\n",
      "     16       \u001b[36m13.3198\u001b[0m  0.0108\n",
      "     17       \u001b[36m12.7670\u001b[0m  0.0155\n",
      "     18       \u001b[36m12.2035\u001b[0m  0.0090\n",
      "     19       \u001b[36m11.6320\u001b[0m  0.0152\n",
      "     20       \u001b[36m11.0565\u001b[0m  0.0097\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m12.3470\u001b[0m  0.0105\n",
      "      2       \u001b[36m12.0612\u001b[0m  0.0162\n",
      "      3       \u001b[36m11.7759\u001b[0m  0.0179\n",
      "      4       \u001b[36m11.4946\u001b[0m  0.0115\n",
      "      5       \u001b[36m11.2156\u001b[0m  0.0158\n",
      "      6       \u001b[36m10.9408\u001b[0m  0.0090\n",
      "      7       \u001b[36m10.6705\u001b[0m  0.0147\n",
      "      8       \u001b[36m10.4048\u001b[0m  0.0160\n",
      "      9       \u001b[36m10.1451\u001b[0m  0.0121\n",
      "     10        \u001b[36m9.8915\u001b[0m  0.0151\n",
      "     11        \u001b[36m9.6436\u001b[0m  0.0169\n",
      "     12        \u001b[36m9.3990\u001b[0m  0.0185\n",
      "     13        \u001b[36m9.1681\u001b[0m  0.0089\n",
      "     14        \u001b[36m8.9341\u001b[0m  0.0096\n",
      "     15        \u001b[36m8.7098\u001b[0m  0.0194\n",
      "     16        \u001b[36m8.4926\u001b[0m  0.0223\n",
      "     17        \u001b[36m8.2804\u001b[0m  0.0216\n",
      "     18        \u001b[36m8.0748\u001b[0m  0.0104\n",
      "     19        \u001b[36m7.8753\u001b[0m  0.0266\n",
      "     20        \u001b[36m7.6810\u001b[0m  0.0271\n",
      "\n",
      " gs.best_score_ = -8.30648235845144, gs.best_params = {'lr': 0.01, 'max_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "}\n",
    "gs = GridSearchCV(GP, params, refit=False, cv=3, scoring='r2', \n",
    "                  return_train_score=False)  #  Use a different scoring function maybe?\n",
    "\n",
    "gs.fit(X=train_x, y=train_y)\n",
    "print('\\n gs.best_score_ = {}, gs.best_params = {}'.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Need to comment out **line 157 - 161** of `.../anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/__init__.py`\n",
    "```\n",
    "if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n",
    "                           indices.dtype.kind == 'i'):\n",
    "    # This is often substantially faster than X[indices]\n",
    "    return X.take(indices, axis=0)\n",
    "else:\n",
    "```\n",
    "Otherwise an error would occur saying\n",
    "`argument 'index' (position 1) must be Tensor, not numpy.ndarray`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
